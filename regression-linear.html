<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>9 Linear regression | Introduction to R</title>
  <meta name="description" content="This is the material for the course Introduction to R, given at Karolinska Institutet, Stockholm, Sweden, as part of the doctoral program in epidemiology." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="9 Linear regression | Introduction to R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is the material for the course Introduction to R, given at Karolinska Institutet, Stockholm, Sweden, as part of the doctoral program in epidemiology." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="9 Linear regression | Introduction to R" />
  
  <meta name="twitter:description" content="This is the material for the course Introduction to R, given at Karolinska Institutet, Stockholm, Sweden, as part of the doctoral program in epidemiology." />
  



<meta name="date" content="2022-03-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="basic-stats-epi.html"/>
<link rel="next" href="regression-other.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this document</a></li>
<li class="part"><span><b>I Getting started</b></span></li>
<li class="chapter" data-level="1" data-path="background.html"><a href="background.html"><i class="fa fa-check"></i><b>1</b> Background</a>
<ul>
<li class="chapter" data-level="1.1" data-path="background.html"><a href="background.html#what-is-r"><i class="fa fa-check"></i><b>1.1</b> What is R?</a></li>
<li class="chapter" data-level="1.2" data-path="background.html"><a href="background.html#what-is-rstudio"><i class="fa fa-check"></i><b>1.2</b> What is RStudio?</a></li>
<li class="chapter" data-level="1.3" data-path="background.html"><a href="background.html#software-installation"><i class="fa fa-check"></i><b>1.3</b> Software installation</a></li>
<li class="chapter" data-level="1.4" data-path="background.html"><a href="background.html#references"><i class="fa fa-check"></i><b>1.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Working with R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#starting-r"><i class="fa fa-check"></i><b>2.1</b> Starting R</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#storing-data-as-objects"><i class="fa fa-check"></i><b>2.2</b> Storing data as objects</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="introduction.html"><a href="introduction.html#about-variable-names"><i class="fa fa-check"></i><b>2.2.1</b> About variable names</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#data-structure-i-the-vector"><i class="fa fa-check"></i><b>2.3</b> Data structure I: The vector</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="introduction.html"><a href="introduction.html#example-simple-descriptives"><i class="fa fa-check"></i><b>2.3.1</b> Example: simple descriptives</a></li>
<li class="chapter" data-level="2.3.2" data-path="introduction.html"><a href="introduction.html#example-simple-plots"><i class="fa fa-check"></i><b>2.3.2</b> Example: simple plots</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#non-numeric-data"><i class="fa fa-check"></i><b>2.4</b> Non-numeric data</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="introduction.html"><a href="introduction.html#descriptives-for-grouping-data"><i class="fa fa-check"></i><b>2.4.1</b> Descriptives for grouping data</a></li>
<li class="chapter" data-level="2.4.2" data-path="introduction.html"><a href="introduction.html#character-vector-vs-factor"><i class="fa fa-check"></i><b>2.4.2</b> Character vector vs factor</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#general-data-in-r"><i class="fa fa-check"></i><b>2.5</b> General data in R</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="introduction.html"><a href="introduction.html#extracting-parts-of-a-data-frame"><i class="fa fa-check"></i><b>2.5.1</b> Extracting parts of a data frame</a></li>
<li class="chapter" data-level="2.5.2" data-path="introduction.html"><a href="introduction.html#ex_desc_stats"><i class="fa fa-check"></i><b>2.5.2</b> Example: descriptive statistics</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="introduction.html"><a href="introduction.html#importing-data"><i class="fa fa-check"></i><b>2.6</b> Importing data</a></li>
<li class="chapter" data-level="2.7" data-path="introduction.html"><a href="introduction.html#meta-activity"><i class="fa fa-check"></i><b>2.7</b> Meta-activity</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="introduction.html"><a href="introduction.html#getting-help"><i class="fa fa-check"></i><b>2.7.1</b> Getting help</a></li>
<li class="chapter" data-level="2.7.2" data-path="introduction.html"><a href="introduction.html#keeping-track-of-objects"><i class="fa fa-check"></i><b>2.7.2</b> Keeping track of objects</a></li>
<li class="chapter" data-level="2.7.3" data-path="introduction.html"><a href="introduction.html#quitting-r"><i class="fa fa-check"></i><b>2.7.3</b> Quitting R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="intro_rstudio.html"><a href="intro_rstudio.html"><i class="fa fa-check"></i><b>3</b> Working in RStudio</a>
<ul>
<li class="chapter" data-level="3.1" data-path="intro_rstudio.html"><a href="intro_rstudio.html#getting-started"><i class="fa fa-check"></i><b>3.1</b> Getting started</a></li>
<li class="chapter" data-level="3.2" data-path="intro_rstudio.html"><a href="intro_rstudio.html#a-quick-tour-of-the-gui"><i class="fa fa-check"></i><b>3.2</b> A quick tour of the GUI</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="intro_rstudio.html"><a href="intro_rstudio.html#console-and-friends"><i class="fa fa-check"></i><b>3.2.1</b> Console and friends</a></li>
<li class="chapter" data-level="3.2.2" data-path="intro_rstudio.html"><a href="intro_rstudio.html#rstudio-console-specials"><i class="fa fa-check"></i><b>3.2.2</b> RStudio Console specials</a></li>
<li class="chapter" data-level="3.2.3" data-path="intro_rstudio.html"><a href="intro_rstudio.html#navigating-the-pane-layout"><i class="fa fa-check"></i><b>3.2.3</b> Navigating the pane layout</a></li>
<li class="chapter" data-level="3.2.4" data-path="intro_rstudio.html"><a href="intro_rstudio.html#the-default-upper-pane"><i class="fa fa-check"></i><b>3.2.4</b> The default upper pane</a></li>
<li class="chapter" data-level="3.2.5" data-path="intro_rstudio.html"><a href="intro_rstudio.html#the-default-lower-pane"><i class="fa fa-check"></i><b>3.2.5</b> The default lower pane</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="intro_rstudio.html"><a href="intro_rstudio.html#source-pane-scripting"><i class="fa fa-check"></i><b>3.3</b> Source pane &amp; scripting</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="intro_rstudio.html"><a href="intro_rstudio.html#console2source"><i class="fa fa-check"></i><b>3.3.1</b> From console to source</a></li>
<li class="chapter" data-level="3.3.2" data-path="intro_rstudio.html"><a href="intro_rstudio.html#the-source-pane-file-editor"><i class="fa fa-check"></i><b>3.3.2</b> The Source pane file editor</a></li>
<li class="chapter" data-level="3.3.3" data-path="intro_rstudio.html"><a href="intro_rstudio.html#displays"><i class="fa fa-check"></i><b>3.3.3</b> Displays</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="intro-example.html"><a href="intro-example.html"><i class="fa fa-check"></i><b>4</b> A simple example</a>
<ul>
<li class="chapter" data-level="4.1" data-path="intro-example.html"><a href="intro-example.html#data-import"><i class="fa fa-check"></i><b>4.1</b> Data import</a></li>
<li class="chapter" data-level="4.2" data-path="intro-example.html"><a href="intro-example.html#analysis"><i class="fa fa-check"></i><b>4.2</b> Analysis</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="intro-example.html"><a href="intro-example.html#desc-ex"><i class="fa fa-check"></i><b>4.2.1</b> Descriptives</a></li>
<li class="chapter" data-level="4.2.2" data-path="intro-example.html"><a href="intro-example.html#blood-pressure-by-salt-intake"><i class="fa fa-check"></i><b>4.2.2</b> Blood pressure by salt intake</a></li>
<li class="chapter" data-level="4.2.3" data-path="intro-example.html"><a href="intro-example.html#salt-intake-by-sex"><i class="fa fa-check"></i><b>4.2.3</b> Salt intake by sex</a></li>
<li class="chapter" data-level="4.2.4" data-path="intro-example.html"><a href="intro-example.html#save-results"><i class="fa fa-check"></i><b>4.2.4</b> Save results</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="intro-example.html"><a href="intro-example.html#turning-into-script"><i class="fa fa-check"></i><b>4.3</b> Turning it into a script</a></li>
<li class="chapter" data-level="4.4" data-path="intro-example.html"><a href="intro-example.html#exp-res"><i class="fa fa-check"></i><b>4.4</b> Exporting results</a></li>
</ul></li>
<li class="part"><span><b>II Working with data</b></span></li>
<li class="chapter" data-level="5" data-path="data-types-struct.html"><a href="data-types-struct.html"><i class="fa fa-check"></i><b>5</b> Data types and structures</a>
<ul>
<li class="chapter" data-level="5.1" data-path="data-types-struct.html"><a href="data-types-struct.html#overview"><i class="fa fa-check"></i><b>5.1</b> Overview</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="data-types-struct.html"><a href="data-types-struct.html#data-examples"><i class="fa fa-check"></i><b>5.1.1</b> Data examples</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="data-types-struct.html"><a href="data-types-struct.html#background-1"><i class="fa fa-check"></i><b>5.2</b> Background</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="data-types-struct.html"><a href="data-types-struct.html#recap"><i class="fa fa-check"></i><b>5.2.1</b> Recap</a></li>
<li class="chapter" data-level="5.2.2" data-path="data-types-struct.html"><a href="data-types-struct.html#motivation"><i class="fa fa-check"></i><b>5.2.2</b> Motivation</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="data-types-struct.html"><a href="data-types-struct.html#more-about-vectors"><i class="fa fa-check"></i><b>5.3</b> More about vectors</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="data-types-struct.html"><a href="data-types-struct.html#vector-calculations"><i class="fa fa-check"></i><b>5.3.1</b> Vector calculations</a></li>
<li class="chapter" data-level="5.3.2" data-path="data-types-struct.html"><a href="data-types-struct.html#indexing-vectors-by-position"><i class="fa fa-check"></i><b>5.3.2</b> Indexing vectors by position</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="data-types-struct.html"><a href="data-types-struct.html#logical-data"><i class="fa fa-check"></i><b>5.4</b> Logical data</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="data-types-struct.html"><a href="data-types-struct.html#definition"><i class="fa fa-check"></i><b>5.4.1</b> Definition</a></li>
<li class="chapter" data-level="5.4.2" data-path="data-types-struct.html"><a href="data-types-struct.html#logical-expressions"><i class="fa fa-check"></i><b>5.4.2</b> Logical expressions</a></li>
<li class="chapter" data-level="5.4.3" data-path="data-types-struct.html"><a href="data-types-struct.html#logical-vectors"><i class="fa fa-check"></i><b>5.4.3</b> Logical vectors</a></li>
<li class="chapter" data-level="5.4.4" data-path="data-types-struct.html"><a href="data-types-struct.html#logical-vectors-for-indexing"><i class="fa fa-check"></i><b>5.4.4</b> Logical vectors for indexing</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="data-types-struct.html"><a href="data-types-struct.html#more-on-rectangular-data"><i class="fa fa-check"></i><b>5.5</b> More on rectangular data</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="data-types-struct.html"><a href="data-types-struct.html#data-frame"><i class="fa fa-check"></i><b>5.5.1</b> Data frame</a></li>
<li class="chapter" data-level="5.5.2" data-path="data-types-struct.html"><a href="data-types-struct.html#matrix"><i class="fa fa-check"></i><b>5.5.2</b> Matrix</a></li>
<li class="chapter" data-level="5.5.3" data-path="data-types-struct.html"><a href="data-types-struct.html#extensions-alternatives"><i class="fa fa-check"></i><b>5.5.3</b> Extensions &amp; alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="data-types-struct.html"><a href="data-types-struct.html#helpers-subset-and-transform"><i class="fa fa-check"></i><b>5.6</b> Helpers: <code>subset</code> and <code>transform</code></a></li>
<li class="chapter" data-level="5.7" data-path="data-types-struct.html"><a href="data-types-struct.html#list-struct"><i class="fa fa-check"></i><b>5.7</b> Free-style data: lists</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="data-types-struct.html"><a href="data-types-struct.html#background-2"><i class="fa fa-check"></i><b>5.7.1</b> Background</a></li>
<li class="chapter" data-level="5.7.2" data-path="data-types-struct.html"><a href="data-types-struct.html#basic_lists"><i class="fa fa-check"></i><b>5.7.2</b> Basic list</a></li>
<li class="chapter" data-level="5.7.3" data-path="data-types-struct.html"><a href="data-types-struct.html#named_lists"><i class="fa fa-check"></i><b>5.7.3</b> Named lists</a></li>
<li class="chapter" data-level="5.7.4" data-path="data-types-struct.html"><a href="data-types-struct.html#example-data-frames"><i class="fa fa-check"></i><b>5.7.4</b> Example: data frames</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="data-types-struct.html"><a href="data-types-struct.html#technical-notes"><i class="fa fa-check"></i><b>5.8</b> Technical notes</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="data-processing.html"><a href="data-processing.html"><i class="fa fa-check"></i><b>6</b> Processing data</a>
<ul>
<li class="chapter" data-level="6.1" data-path="data-processing.html"><a href="data-processing.html#overview-1"><i class="fa fa-check"></i><b>6.1</b> Overview</a></li>
<li class="chapter" data-level="6.2" data-path="data-processing.html"><a href="data-processing.html#group-stats"><i class="fa fa-check"></i><b>6.2</b> Groupwise statistics</a></li>
<li class="chapter" data-level="6.3" data-path="data-processing.html"><a href="data-processing.html#own-functions"><i class="fa fa-check"></i><b>6.3</b> Using your own functions</a></li>
<li class="chapter" data-level="6.4" data-path="data-processing.html"><a href="data-processing.html#split-apply-combine"><i class="fa fa-check"></i><b>6.4</b> Split - Apply - Combine</a></li>
<li class="chapter" data-level="6.5" data-path="data-processing.html"><a href="data-processing.html#merge-data-base"><i class="fa fa-check"></i><b>6.5</b> Merging data sets</a></li>
<li class="chapter" data-level="6.6" data-path="data-processing.html"><a href="data-processing.html#general-pipeline"><i class="fa fa-check"></i><b>6.6</b> Using pipelines</a></li>
<li class="chapter" data-level="6.7" data-path="data-processing.html"><a href="data-processing.html#technical-notes-1"><i class="fa fa-check"></i><b>6.7</b> Technical notes</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="data-tidyverse.html"><a href="data-tidyverse.html"><i class="fa fa-check"></i><b>7</b> The <code>tidyverse</code></a>
<ul>
<li class="chapter" data-level="7.1" data-path="data-tidyverse.html"><a href="data-tidyverse.html#overview-2"><i class="fa fa-check"></i><b>7.1</b> Overview</a></li>
<li class="chapter" data-level="7.2" data-path="data-tidyverse.html"><a href="data-tidyverse.html#example-using-dplyr-for-data-processing"><i class="fa fa-check"></i><b>7.2</b> Example: Using <code>dplyr</code> for data processing</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="data-tidyverse.html"><a href="data-tidyverse.html#overview-3"><i class="fa fa-check"></i><b>7.2.1</b> Overview</a></li>
<li class="chapter" data-level="7.2.2" data-path="data-tidyverse.html"><a href="data-tidyverse.html#basic-data-operations"><i class="fa fa-check"></i><b>7.2.2</b> Basic data operations</a></li>
<li class="chapter" data-level="7.2.3" data-path="data-tidyverse.html"><a href="data-tidyverse.html#groupwise-data-operations"><i class="fa fa-check"></i><b>7.2.3</b> Groupwise data operations</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="data-tidyverse.html"><a href="data-tidyverse.html#tidyverse-vs-base-r"><i class="fa fa-check"></i><b>7.3</b> <code>tidyverse</code> vs base R?</a></li>
<li class="chapter" data-level="7.4" data-path="data-tidyverse.html"><a href="data-tidyverse.html#technical-notes-2"><i class="fa fa-check"></i><b>7.4</b> Technical notes</a></li>
</ul></li>
<li class="part"><span><b>III Estimation, inference, modelling</b></span></li>
<li class="chapter" data-level="8" data-path="basic-stats-epi.html"><a href="basic-stats-epi.html"><i class="fa fa-check"></i><b>8</b> Basic Statistics &amp; Epidemiology</a>
<ul>
<li class="chapter" data-level="8.1" data-path="basic-stats-epi.html"><a href="basic-stats-epi.html#descriptives"><i class="fa fa-check"></i><b>8.1</b> Descriptive statistics</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="basic-stats-epi.html"><a href="basic-stats-epi.html#base-desc"><i class="fa fa-check"></i><b>8.1.1</b> In base R</a></li>
<li class="chapter" data-level="8.1.2" data-path="basic-stats-epi.html"><a href="basic-stats-epi.html#using-package-summarytools"><i class="fa fa-check"></i><b>8.1.2</b> Using package <code>summarytools</code></a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="basic-stats-epi.html"><a href="basic-stats-epi.html#confidence-intervals"><i class="fa fa-check"></i><b>8.2</b> Confidence intervals</a></li>
<li class="chapter" data-level="8.3" data-path="basic-stats-epi.html"><a href="basic-stats-epi.html#statistical-tests"><i class="fa fa-check"></i><b>8.3</b> Statistical tests</a></li>
<li class="chapter" data-level="8.4" data-path="basic-stats-epi.html"><a href="basic-stats-epi.html#epidemiological-risk-measures"><i class="fa fa-check"></i><b>8.4</b> Epidemiological risk measures</a></li>
<li class="chapter" data-level="8.5" data-path="basic-stats-epi.html"><a href="basic-stats-epi.html#pander-intro"><i class="fa fa-check"></i><b>8.5</b> Improved display of descriptives</a></li>
<li class="chapter" data-level="8.6" data-path="basic-stats-epi.html"><a href="basic-stats-epi.html#next-steps"><i class="fa fa-check"></i><b>8.6</b> Next steps</a></li>
<li class="chapter" data-level="8.7" data-path="basic-stats-epi.html"><a href="basic-stats-epi.html#technical-notes-3"><i class="fa fa-check"></i><b>8.7</b> Technical notes</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="regression-linear.html"><a href="regression-linear.html"><i class="fa fa-check"></i><b>9</b> Linear regression</a>
<ul>
<li class="chapter" data-level="9.1" data-path="regression-linear.html"><a href="regression-linear.html#overview-4"><i class="fa fa-check"></i><b>9.1</b> Overview</a></li>
<li class="chapter" data-level="9.2" data-path="regression-linear.html"><a href="regression-linear.html#background-3"><i class="fa fa-check"></i><b>9.2</b> Background</a></li>
<li class="chapter" data-level="9.3" data-path="regression-linear.html"><a href="regression-linear.html#simple-linear-regression"><i class="fa fa-check"></i><b>9.3</b> Simple linear regression</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="regression-linear.html"><a href="regression-linear.html#scatter-loess"><i class="fa fa-check"></i><b>9.3.1</b> Looking at the data</a></li>
<li class="chapter" data-level="9.3.2" data-path="regression-linear.html"><a href="regression-linear.html#fitting-a-linear-regression-model"><i class="fa fa-check"></i><b>9.3.2</b> Fitting a linear regression model</a></li>
<li class="chapter" data-level="9.3.3" data-path="regression-linear.html"><a href="regression-linear.html#regression-table-and-inference"><i class="fa fa-check"></i><b>9.3.3</b> Regression table and inference</a></li>
<li class="chapter" data-level="9.3.4" data-path="regression-linear.html"><a href="regression-linear.html#prediction"><i class="fa fa-check"></i><b>9.3.4</b> Prediction</a></li>
<li class="chapter" data-level="9.3.5" data-path="regression-linear.html"><a href="regression-linear.html#diagnostics"><i class="fa fa-check"></i><b>9.3.5</b> Diagnostics</a></li>
<li class="chapter" data-level="9.3.6" data-path="regression-linear.html"><a href="regression-linear.html#binary-predictor-and-dummy-coding"><i class="fa fa-check"></i><b>9.3.6</b> Binary predictor and dummy coding</a></li>
<li class="chapter" data-level="9.3.7" data-path="regression-linear.html"><a href="regression-linear.html#nicer-regression-tables"><i class="fa fa-check"></i><b>9.3.7</b> Nicer regression tables</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="regression-linear.html"><a href="regression-linear.html#multiple-linear-regression"><i class="fa fa-check"></i><b>9.4</b> Multiple linear regression</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="regression-linear.html"><a href="regression-linear.html#multiple-predictors"><i class="fa fa-check"></i><b>9.4.1</b> Multiple predictors</a></li>
<li class="chapter" data-level="9.4.2" data-path="regression-linear.html"><a href="regression-linear.html#categorical-predictors-with-2-levels"><i class="fa fa-check"></i><b>9.4.2</b> Categorical predictors with <span class="math inline">\(&gt;\)</span> 2 levels</a></li>
<li class="chapter" data-level="9.4.3" data-path="regression-linear.html"><a href="regression-linear.html#interactions"><i class="fa fa-check"></i><b>9.4.3</b> Interactions</a></li>
<li class="chapter" data-level="9.4.4" data-path="regression-linear.html"><a href="regression-linear.html#splines"><i class="fa fa-check"></i><b>9.4.4</b> Splines</a></li>
<li class="chapter" data-level="9.4.5" data-path="regression-linear.html"><a href="regression-linear.html#model-comparisons"><i class="fa fa-check"></i><b>9.4.5</b> Model comparisons</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="regression-linear.html"><a href="regression-linear.html#technical-notes-4"><i class="fa fa-check"></i><b>9.5</b> Technical notes</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="regression-other.html"><a href="regression-other.html"><i class="fa fa-check"></i><b>10</b> More regression models</a>
<ul>
<li class="chapter" data-level="10.1" data-path="regression-other.html"><a href="regression-other.html#logistic-regression"><i class="fa fa-check"></i><b>10.1</b> Logistic regression</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="regression-other.html"><a href="regression-other.html#ex.-birthweight-uterine-irritability"><i class="fa fa-check"></i><b>10.1.1</b> Ex.: Birthweight &amp; uterine irritability</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="regression-other.html"><a href="regression-other.html#survival-regression"><i class="fa fa-check"></i><b>10.2</b> Survival regression</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="regression-other.html"><a href="regression-other.html#survival-data"><i class="fa fa-check"></i><b>10.2.1</b> Survival data</a></li>
<li class="chapter" data-level="10.2.2" data-path="regression-other.html"><a href="regression-other.html#survival-curves"><i class="fa fa-check"></i><b>10.2.2</b> Survival curves</a></li>
<li class="chapter" data-level="10.2.3" data-path="regression-other.html"><a href="regression-other.html#cox-regression"><i class="fa fa-check"></i><b>10.2.3</b> Cox regression</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="regression-other.html"><a href="regression-other.html#other-models"><i class="fa fa-check"></i><b>10.3</b> Other models</a></li>
</ul></li>
<li class="part"><span><b>IV Graphics</b></span></li>
<li class="chapter" data-level="11" data-path="graphics-base.html"><a href="graphics-base.html"><i class="fa fa-check"></i><b>11</b> Graphics in base R</a>
<ul>
<li class="chapter" data-level="11.1" data-path="graphics-base.html"><a href="graphics-base.html#overview-5"><i class="fa fa-check"></i><b>11.1</b> Overview</a></li>
<li class="chapter" data-level="11.2" data-path="graphics-base.html"><a href="graphics-base.html#base-plots"><i class="fa fa-check"></i><b>11.2</b> Base plots</a>
<ul>
<li class="chapter" data-level="" data-path="graphics-base.html"><a href="graphics-base.html#vectorized-graphical-parameters"><i class="fa fa-check"></i>Vectorized graphical parameters</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="graphics-base.html"><a href="graphics-base.html#low-level-and-high-level-plotting"><i class="fa fa-check"></i><b>11.3</b> Low-level and high-level plotting</a></li>
<li class="chapter" data-level="11.4" data-path="graphics-base.html"><a href="graphics-base.html#displaying-saving-coloring-plots"><i class="fa fa-check"></i><b>11.4</b> Displaying, saving, coloring plots</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="graphics-ggplot2.html"><a href="graphics-ggplot2.html"><i class="fa fa-check"></i><b>12</b> Graphics using <code>ggplot2</code></a>
<ul>
<li class="chapter" data-level="12.1" data-path="graphics-ggplot2.html"><a href="graphics-ggplot2.html#overview-6"><i class="fa fa-check"></i><b>12.1</b> Overview</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="graphics-ggplot2.html"><a href="graphics-ggplot2.html#data-example-hemoglobin"><i class="fa fa-check"></i><b>12.1.1</b> Data example: Hemoglobin</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="graphics-ggplot2.html"><a href="graphics-ggplot2.html#background-4"><i class="fa fa-check"></i><b>12.2</b> Background</a></li>
<li class="chapter" data-level="12.3" data-path="graphics-ggplot2.html"><a href="graphics-ggplot2.html#concepts"><i class="fa fa-check"></i><b>12.3</b> Concepts</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="graphics-ggplot2.html"><a href="graphics-ggplot2.html#aesthetics"><i class="fa fa-check"></i><b>12.3.1</b> Aesthetics</a></li>
<li class="chapter" data-level="12.3.2" data-path="graphics-ggplot2.html"><a href="graphics-ggplot2.html#example-data"><i class="fa fa-check"></i><b>12.3.2</b> Example data</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="graphics-ggplot2.html"><a href="graphics-ggplot2.html#background-5"><i class="fa fa-check"></i><b>12.4</b> Background</a></li>
<li class="chapter" data-level="12.5" data-path="graphics-ggplot2.html"><a href="graphics-ggplot2.html#basic-usage"><i class="fa fa-check"></i><b>12.5</b> Basic usage</a></li>
<li class="chapter" data-level="12.6" data-path="graphics-ggplot2.html"><a href="graphics-ggplot2.html#slightly-extended-usage"><i class="fa fa-check"></i><b>12.6</b> Slightly extended usage</a></li>
<li class="chapter" data-level="12.7" data-path="graphics-ggplot2.html"><a href="graphics-ggplot2.html#multiple-layers"><i class="fa fa-check"></i><b>12.7</b> Multiple layers</a></li>
<li class="chapter" data-level="12.8" data-path="graphics-ggplot2.html"><a href="graphics-ggplot2.html#splitting-the-plot"><i class="fa fa-check"></i><b>12.8</b> Splitting the plot</a></li>
<li class="chapter" data-level="12.9" data-path="graphics-ggplot2.html"><a href="graphics-ggplot2.html#messing-with-the-defaults"><i class="fa fa-check"></i><b>12.9</b> Messing with the defaults</a>
<ul>
<li class="chapter" data-level="12.9.1" data-path="graphics-ggplot2.html"><a href="graphics-ggplot2.html#fixing-aesthetics"><i class="fa fa-check"></i><b>12.9.1</b> {-} Fixing aesthetics</a></li>
<li class="chapter" data-level="" data-path="graphics-ggplot2.html"><a href="graphics-ggplot2.html#scales"><i class="fa fa-check"></i>Scales</a></li>
</ul></li>
<li class="chapter" data-level="12.10" data-path="graphics-ggplot2.html"><a href="graphics-ggplot2.html#messing-with-defaults-ii-themes"><i class="fa fa-check"></i><b>12.10</b> Messing with defaults II: themes</a></li>
<li class="chapter" data-level="12.11" data-path="graphics-ggplot2.html"><a href="graphics-ggplot2.html#extension-packages"><i class="fa fa-check"></i><b>12.11</b> Extension packages</a></li>
<li class="chapter" data-level="12.12" data-path="graphics-ggplot2.html"><a href="graphics-ggplot2.html#technical-notes-5"><i class="fa fa-check"></i><b>12.12</b> Technical notes</a></li>
</ul></li>
<li class="part"><span><b>V Organizing the analysis</b></span></li>
<li class="chapter" data-level="13" data-path="tables-nice.html"><a href="tables-nice.html"><i class="fa fa-check"></i><b>13</b> Generating nice tables</a></li>
<li class="chapter" data-level="14" data-path="dynamic-documents.html"><a href="dynamic-documents.html"><i class="fa fa-check"></i><b>14</b> Dynamic documents</a></li>
<li class="chapter" data-level="15" data-path="scripting-workflow.html"><a href="scripting-workflow.html"><i class="fa fa-check"></i><b>15</b> Scripting and workflow</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regression-linear" class="section level1" number="9">
<h1><span class="header-section-number">9</span> Linear regression</h1>
<div id="overview-4" class="section level2" number="9.1">
<h2><span class="header-section-number">9.1</span> Overview</h2>
<p>We study linear regression as a template for regression modelling in R, and follow the workflow of fitting a simple model to data, extracting relevant information about the fitted model, and making predictions from it. We complement this with some descriptive and diagnostic graphical displays. In the second part, we look at different ways of generalizing to multi-predictor models, including models with interaction terms, dummy coding of discrete (factorial) predictors, and spline terms.</p>
<p>For our examples, we use data from a small clinical study, where 20 women provided blood samples which were analysed for hemoglobin level (in g/dl) and packed cell volume (PCV, in %). The results, together with age and menopausal status of the women, are recorded in file <code>Hemoglobin.txt</code> which has been imported into a R as data frame <code>hemoglobin</code>.</p>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb198-1"><a href="regression-linear.html#cb198-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">str</span>(hemoglobin)</span>
<span id="cb198-2"><a href="regression-linear.html#cb198-2" aria-hidden="true" tabindex="-1"></a><span class="st">&#39;data.frame&#39;</span><span class="sc">:</span>   <span class="dv">20</span> obs. of  <span class="dv">4</span> variables<span class="sc">:</span></span>
<span id="cb198-3"><a href="regression-linear.html#cb198-3" aria-hidden="true" tabindex="-1"></a> <span class="er">$</span> Hb       <span class="sc">:</span> num  <span class="fl">11.1</span> <span class="fl">10.7</span> <span class="fl">12.4</span> <span class="dv">14</span> <span class="fl">13.1</span> <span class="fl">10.5</span> <span class="fl">9.6</span> <span class="fl">12.5</span> <span class="fl">13.5</span> <span class="fl">13.9</span> ...</span>
<span id="cb198-4"><a href="regression-linear.html#cb198-4" aria-hidden="true" tabindex="-1"></a> <span class="sc">$</span> PCV      <span class="sc">:</span> int  <span class="dv">35</span> <span class="dv">45</span> <span class="dv">47</span> <span class="dv">50</span> <span class="dv">31</span> <span class="dv">30</span> <span class="dv">25</span> <span class="dv">33</span> <span class="dv">35</span> <span class="dv">40</span> ...</span>
<span id="cb198-5"><a href="regression-linear.html#cb198-5" aria-hidden="true" tabindex="-1"></a> <span class="sc">$</span> Age      <span class="sc">:</span> int  <span class="dv">20</span> <span class="dv">22</span> <span class="dv">25</span> <span class="dv">28</span> <span class="dv">28</span> <span class="dv">31</span> <span class="dv">32</span> <span class="dv">35</span> <span class="dv">38</span> <span class="dv">40</span> ...</span>
<span id="cb198-6"><a href="regression-linear.html#cb198-6" aria-hidden="true" tabindex="-1"></a> <span class="sc">$</span> Menopause<span class="sc">:</span> Factor w<span class="sc">/</span> <span class="dv">2</span> levels <span class="st">&quot;No&quot;</span>,<span class="st">&quot;Yes&quot;</span><span class="sc">:</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">2</span> ...</span></code></pre></div>
<p>The primary question of interest is how hemoglobin levels vary as a function of PCV, possibly adjusted for the other variables.</p>
</div>
<div id="background-3" class="section level2" number="9.2">
<h2><span class="header-section-number">9.2</span> Background</h2>
<p>Linear regression in itself is not the most common class of regression models used in epidemiology. However, all common models like logistic regression or Cox proportional hazard models, as well as many other models (Poisson, log-binomial, negative binomial, flexible parametric survival etc.) generalize the same basic idea that at some specific scale, the relationship between outcome and predictor(s) is linear - in other words, a constant increase in a predictor leads to a constant and proportional change in an outcome, or risk of an outcome. This assumption is intuitive, visually attractive, and often at least approximately and/or locally appropriate.</p>
<p>Part of the appeal is that simple linear regression models with only one predictor can easily be extended to include multiple predictors. Conceptually, this is a big step in epidemiology, as it allows discussing and addressing confounding through adjustment, but from a model building perspective, the principle is straightforward: we have an outcome of interest on the left hand side of an equation, and a weighted sum of predictors on the right hand side, and we want to choose the weights for the predictors so that the two sides agree as closely as possible. In this setting, new predictors enter the equation on a democratic basis: each gets their own parameter, and is otherwise allowed to contribute to the right hand side in exactly the same manner as all other predictors.<a href="#fn44" class="footnote-ref" id="fnref44"><sup>44</sup></a></p>
<p>These attractive properties have motivated the definition of many derived models, including those listed above: we take a suitably transformed outcome (not necessarily continuous) and relate it to a suitably transformed weighted sum of predictors, where the nature of the relationship is determined by the (assumed) probability distribution of the outcome. This often manages to preserve much of the original linear model goodness.</p>
<p>Important for our purposes, this holds not only on an abstract mathematical level, but quite generally also for the implementation and interface of models in statistical software. The core concept in R is the specification of a model relationship through a <em>formula</em> that relates a dependent left hand side to one or several predictors on the rioght hand side of the model equation.</p>
</div>
<div id="simple-linear-regression" class="section level2" number="9.3">
<h2><span class="header-section-number">9.3</span> Simple linear regression</h2>
<p>The equation below shows the most basic situation mathematically, though the terminology often varies: we want to relate a <em>dependent variable</em> (or outcome, or response, commonly referred to as <span class="math inline">\(y\)</span>) to one <em>independent variable</em> (or predictor, or covariate, commonly referred to as <span class="math inline">\(x\)</span>). We can write this as
<span class="math display">\[
y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]</span>
where the index <span class="math inline">\(i\)</span> refers to an observation (<span class="math inline">\(i \in 1\ldots n\)</span>), <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are <em>regression coefficients</em> or <em>parameters</em> of the model (corresponding to intercept and slope of the regression line), and <span class="math inline">\(\epsilon_i\)</span> is a subject-specific random variable (<em>‘error’</em>) generally assumed to be (approximately) normally distributed with mean 0 and some unknown but fixed variance <span class="math inline">\(\sigma^2\)</span>.</p>
<div id="scatter-loess" class="section level3" number="9.3.1">
<h3><span class="header-section-number">9.3.1</span> Looking at the data</h3>
<p>The canonical display of a simple linear regression is the <em>scatterplot</em>, where by convention the dependent variable is plotted on the vertical axis:</p>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb199-1"><a href="regression-linear.html#cb199-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">plot</span>(Hb <span class="sc">~</span> PCV, <span class="at">data =</span> hemoglobin)</span></code></pre></div>
<p><img src="introductio-to-r_files/figure-html/unnamed-chunk-209-1.png" width="80%" style="display: block; margin: auto;" />
Here we see a reasonable, but not excessively strong linear relationship between PCV and hemoglobin levels, though this can be somewhat difficult to assess visually based on just a few observations. Note how the plot is specified via a formula relating a left hand side (<code>Hb</code>) to a right hand side (<code>PCV</code>), where the operator <code>~</code> should be read as <em>“as function of”</em>, in the same manner as for boxplots (as described in Section @ref(ex_desc_stats).</p>
<p>R also has the specialized function <code>scatter.smooth</code>, which adds a useful graphical summary of the relationship between x and y, a so-called <em>smoother</em> or <em>smoothing function</em>:</p>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="regression-linear.html#cb200-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">scatter.smooth</span>(hemoglobin<span class="sc">$</span>PCV, hemoglobin<span class="sc">$</span>Hb)</span></code></pre></div>
<p><img src="introductio-to-r_files/figure-html/unnamed-chunk-210-1.png" width="80%" style="display: block; margin: auto;" />
The smoothing line here<a href="#fn45" class="footnote-ref" id="fnref45"><sup>45</sup></a> tries to follow the shape of the association between the two variables. Technically, this is done via fitting regression lines locally, in a moving window, as the animation below demonstrates: at each point, we only use the black, non-shaded points to fit a linear regression between outcome and predictor; moving that window along the predictor variable on the horizontal axis and connecting the predictions from the local regression models, we get a smoothly varying curve that visually summarizes the association.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-211"></span>
<img src="figures/loess.gif" alt="Animated loess smooth example [(Source)](https://simplystatistics.org/posts/2014-02-13-loess-explained-in-a-gif/)" width="50%" />
<p class="caption">
Figure 9.1: Animated loess smooth example <a href="https://simplystatistics.org/posts/2014-02-13-loess-explained-in-a-gif/">(Source)</a>
</p>
</div>
<p>For our example above, we see a mostly linear and increasing association, with a bit of a bump in the middle. At first glance, a linear regression model seems like an acceptable working hypothesis.</p>
</div>
<div id="fitting-a-linear-regression-model" class="section level3" number="9.3.2">
<h3><span class="header-section-number">9.3.2</span> Fitting a linear regression model</h3>
<p>This is the easy part: we simply pass the same formula as above to function <code>lm</code> (for <em>linear model</em>):</p>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb201-1"><a href="regression-linear.html#cb201-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> lm1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Hb <span class="sc">~</span> PCV, <span class="at">data =</span> hemoglobin)</span></code></pre></div>
<p>Printing the linear model object however is not very rewarding:</p>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb202-1"><a href="regression-linear.html#cb202-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> lm1</span>
<span id="cb202-2"><a href="regression-linear.html#cb202-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb202-3"><a href="regression-linear.html#cb202-3" aria-hidden="true" tabindex="-1"></a>Call<span class="sc">:</span></span>
<span id="cb202-4"><a href="regression-linear.html#cb202-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(<span class="at">formula =</span> Hb <span class="sc">~</span> PCV, <span class="at">data =</span> hemoglobin)</span>
<span id="cb202-5"><a href="regression-linear.html#cb202-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb202-6"><a href="regression-linear.html#cb202-6" aria-hidden="true" tabindex="-1"></a>Coefficients<span class="sc">:</span></span>
<span id="cb202-7"><a href="regression-linear.html#cb202-7" aria-hidden="true" tabindex="-1"></a>(Intercept)          PCV  </span>
<span id="cb202-8"><a href="regression-linear.html#cb202-8" aria-hidden="true" tabindex="-1"></a>     <span class="fl">5.5885</span>       <span class="fl">0.2048</span>  </span></code></pre></div>
<p>All we see is the original call to <code>lm</code>, including the specified formula, and the estimated regression coefficients (referred to as <span class="math inline">\({\hat \beta}_0\)</span> and <span class="math inline">\({\hat \beta}_1\)</span> in statistics). However, we have already seen that the actual content of an object and what R prints at the command line are not necessarily the same thing - under the hood, <code>lm1</code> is a complex named list:</p>
<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb203-1"><a href="regression-linear.html#cb203-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">is.list</span>(lm1)</span>
<span id="cb203-2"><a href="regression-linear.html#cb203-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="cn">TRUE</span></span>
<span id="cb203-3"><a href="regression-linear.html#cb203-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">names</span>(lm1)</span>
<span id="cb203-4"><a href="regression-linear.html#cb203-4" aria-hidden="true" tabindex="-1"></a> [<span class="dv">1</span>] <span class="st">&quot;coefficients&quot;</span>  <span class="st">&quot;residuals&quot;</span>     <span class="st">&quot;effects&quot;</span>       <span class="st">&quot;rank&quot;</span>          <span class="st">&quot;fitted.values&quot;</span> <span class="st">&quot;assign&quot;</span>       </span>
<span id="cb203-5"><a href="regression-linear.html#cb203-5" aria-hidden="true" tabindex="-1"></a> [<span class="dv">7</span>] <span class="st">&quot;qr&quot;</span>            <span class="st">&quot;df.residual&quot;</span>   <span class="st">&quot;xlevels&quot;</span>       <span class="st">&quot;call&quot;</span>          <span class="st">&quot;terms&quot;</span>         <span class="st">&quot;model&quot;</span>        </span></code></pre></div>
<p>The very general idea of model fitting in R is that we use a function (of course) to fit the model, save the resulting fit to an object (naturally), and then use a series of helper functions to extract whatever information we are interested in from that object: in the same way that we will use the formula notation to specify a model equation for the fitting function, regardless of model type, we also use the same set of helper functions as below for extracting information across different model types.</p>
</div>
<div id="regression-table-and-inference" class="section level3" number="9.3.3">
<h3><span class="header-section-number">9.3.3</span> Regression table and inference</h3>
<p>The standard way to generate a standard display of a fitted regression model in R is via the function <code>summary</code>: when applied to a regression model, it will generate a table of regression coefficients, but also important statistics and measures for the model as a whole:</p>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb204-1"><a href="regression-linear.html#cb204-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">summary</span>(lm1)</span>
<span id="cb204-2"><a href="regression-linear.html#cb204-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-3"><a href="regression-linear.html#cb204-3" aria-hidden="true" tabindex="-1"></a>Call<span class="sc">:</span></span>
<span id="cb204-4"><a href="regression-linear.html#cb204-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(<span class="at">formula =</span> Hb <span class="sc">~</span> PCV, <span class="at">data =</span> hemoglobin)</span>
<span id="cb204-5"><a href="regression-linear.html#cb204-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-6"><a href="regression-linear.html#cb204-6" aria-hidden="true" tabindex="-1"></a>Residuals<span class="sc">:</span></span>
<span id="cb204-7"><a href="regression-linear.html#cb204-7" aria-hidden="true" tabindex="-1"></a>    Min      1Q  Median      3Q     Max </span>
<span id="cb204-8"><a href="regression-linear.html#cb204-8" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="fl">4.1062</span> <span class="sc">-</span><span class="fl">1.2542</span>  <span class="fl">0.2228</span>  <span class="fl">1.3244</span>  <span class="fl">3.0180</span> </span>
<span id="cb204-9"><a href="regression-linear.html#cb204-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-10"><a href="regression-linear.html#cb204-10" aria-hidden="true" tabindex="-1"></a>Coefficients<span class="sc">:</span></span>
<span id="cb204-11"><a href="regression-linear.html#cb204-11" aria-hidden="true" tabindex="-1"></a>            Estimate Std. Error t value <span class="fu">Pr</span>(<span class="sc">&gt;</span><span class="er">|</span>t<span class="sc">|</span>)   </span>
<span id="cb204-12"><a href="regression-linear.html#cb204-12" aria-hidden="true" tabindex="-1"></a>(Intercept)  <span class="fl">5.58853</span>    <span class="fl">2.24514</span>   <span class="fl">2.489</span>  <span class="fl">0.02282</span> <span class="sc">*</span> </span>
<span id="cb204-13"><a href="regression-linear.html#cb204-13" aria-hidden="true" tabindex="-1"></a>PCV          <span class="fl">0.20484</span>    <span class="fl">0.05301</span>   <span class="fl">3.864</span>  <span class="fl">0.00114</span> <span class="sc">**</span></span>
<span id="cb204-14"><a href="regression-linear.html#cb204-14" aria-hidden="true" tabindex="-1"></a><span class="sc">---</span></span>
<span id="cb204-15"><a href="regression-linear.html#cb204-15" aria-hidden="true" tabindex="-1"></a>Signif. codes<span class="sc">:</span>  <span class="dv">0</span> <span class="st">&#39;***&#39;</span> <span class="fl">0.001</span> <span class="st">&#39;**&#39;</span> <span class="fl">0.01</span> <span class="st">&#39;*&#39;</span> <span class="fl">0.05</span> <span class="st">&#39;.&#39;</span> <span class="fl">0.1</span> <span class="st">&#39; &#39;</span> <span class="dv">1</span></span>
<span id="cb204-16"><a href="regression-linear.html#cb204-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-17"><a href="regression-linear.html#cb204-17" aria-hidden="true" tabindex="-1"></a>Residual standard error<span class="sc">:</span> <span class="fl">1.824</span> on <span class="dv">18</span> degrees of freedom</span>
<span id="cb204-18"><a href="regression-linear.html#cb204-18" aria-hidden="true" tabindex="-1"></a>Multiple R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.4534</span>,    Adjusted R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.4231</span> </span>
<span id="cb204-19"><a href="regression-linear.html#cb204-19" aria-hidden="true" tabindex="-1"></a>F<span class="sc">-</span>statistic<span class="sc">:</span> <span class="fl">14.93</span> on <span class="dv">1</span> and <span class="dv">18</span> DF,  p<span class="sc">-</span>value<span class="sc">:</span> <span class="fl">0.001136</span></span></code></pre></div>
<p>We see four different blocks of output, of different levels of general interest; starting at the top:</p>
<ul>
<li><p>the <em>call</em>, which is as before just the original function call to <code>lm</code>, including the model formula; helpful to keep things orderly when you fit and summarize many different models, possibly with different outcomes (as this is the only place where the response variable is shown), but I usually skip over this part;</p></li>
<li><p>some numerical information on the model <em>residuals</em>; the five-number summary of the residuals can give rough impression of how symmetrically they are distributed around the regression line, but even as a dedicated fan of residuals, I generally ignore this, and look at the diagnostic plots below instead;</p></li>
<li><p>the <em>regression table</em>: a tabular arrangement of the model parameters, which is the standard way of reporting a fitted model in statistical software. In R, we get the estimated value (<code>Estimate</code>) for each parameter, the corresponding standard error of the estimate (<code>Std. Error</code>), the derived Wald test statistic (<code>t value</code>, just the estimate divided by the standard error) and the corresponding p-value for the null hypothesis that the true underlying value of the parameter is really zero (<code>Pr(&gt;|t|)</code>).</p>
<p>So in our specific case, the regression model for hemoglobin as a function of PCV has an estimated intercept of ca. 5.6 g/dl and an estimated slope of ca. 0.20 (g/dl)/%: in other words, the average hemglobin level increases by ca. 0.20 g/dl for each extra % of PCV in the blood. The corresponding p-values for the two parameters are below the usual cutoff of 0.05, so we can conclude in the usual manner that both are statistically significantly different from zero. <a href="#fn46" class="footnote-ref" id="fnref46"><sup>46</sup></a></p></li>
<li><p>A final block with information relating to the model as a whole (instead of individual regression parameters): the residual standard error is just the estimated standard deviation of the error term <span class="math inline">\(\epsilon\)</span>; the coefficient of determination <span class="math inline">\(R^2\)</span> estimates the proportion of variance in the dependent variable that is explained by the regression model - the adjusted <span class="math inline">\(R^2_{adj}\)</span> does the same, but takes into account the number of predictor variables in the model (more powerful models with more predictors get their adjusted <span class="math inline">\(R^2\)</span> deflated). Finally, we have an F-test for the null hypothesis that the regression model as a whole does not explain the response variable better than the simple mean of the response (i.e. an intercept-only model, where the slope of the predictor is zero).<a href="#fn47" class="footnote-ref" id="fnref47"><sup>47</sup></a></p>
<p>For the current simple regression model with one predictor, that is a bit of an overkill: <span class="math inline">\(R^2\)</span> and <span class="math inline">\(R^2_{adj}\)</span> agree that ca. 42-45% of the variance of the hemoglobin values is explained by the model. The F-test allows us to reject the null hypothesis that the association between the hemoglobin level and PCV is a flat line; a closer look shows that the p-value for the F-test is the same as for the t-test for the predictor variable, and an even closer look will show that the reported value of the F-statistic is just the square of the t-statistic - this doesn’t add anything for a simple one-predictor model, but can be useful for multi-predictor models, as discussed below.</p></li>
</ul>
<p>Note that many other statistical software like e.g. Stata will include <em>confidence intervals</em> for the regression parameters in the regression table. In R however, we have to invoke the separate function <code>confint</code> to calculate them:</p>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb205-1"><a href="regression-linear.html#cb205-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">confint</span>(lm1)</span>
<span id="cb205-2"><a href="regression-linear.html#cb205-2" aria-hidden="true" tabindex="-1"></a>                 <span class="fl">2.5</span> <span class="sc">%    97.5 %</span></span>
<span id="cb205-3"><a href="regression-linear.html#cb205-3" aria-hidden="true" tabindex="-1"></a>(Intercept) <span class="fl">0.87166891</span> <span class="fl">10.305386</span></span>
<span id="cb205-4"><a href="regression-linear.html#cb205-4" aria-hidden="true" tabindex="-1"></a>PCV         <span class="fl">0.09347255</span>  <span class="fl">0.316202</span></span></code></pre></div>
<p>For the more mathematically minded, note that we can directly extract the vector of parameter estimates<span class="math inline">\({\hat \beta} = ({\hat \beta}_0, {\hat \beta}_1)\)</span> and the corresponding variance-covariance matrix from the fitted model:</p>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb206-1"><a href="regression-linear.html#cb206-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">coef</span>(lm1)</span>
<span id="cb206-2"><a href="regression-linear.html#cb206-2" aria-hidden="true" tabindex="-1"></a>(Intercept)         PCV </span>
<span id="cb206-3"><a href="regression-linear.html#cb206-3" aria-hidden="true" tabindex="-1"></a>  <span class="fl">5.5885273</span>   <span class="fl">0.2048373</span> </span>
<span id="cb206-4"><a href="regression-linear.html#cb206-4" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">vcov</span>(lm1)</span>
<span id="cb206-5"><a href="regression-linear.html#cb206-5" aria-hidden="true" tabindex="-1"></a>            (Intercept)        PCV</span>
<span id="cb206-6"><a href="regression-linear.html#cb206-6" aria-hidden="true" tabindex="-1"></a>(Intercept)   <span class="fl">5.0406414</span> <span class="sc">-</span><span class="fl">0.1170282</span></span>
<span id="cb206-7"><a href="regression-linear.html#cb206-7" aria-hidden="true" tabindex="-1"></a>PCV          <span class="sc">-</span><span class="fl">0.1170282</span>  <span class="fl">0.0028098</span></span></code></pre></div>
<p>The returned objects are indeed a vector and matrix as R understands them, and can be used for all kinds of exciting linear algebra, if you are into that kind of thing.</p>
<p><strong>Exercise:</strong></p>
<ol style="list-style-type: decimal">
<li>Calculate 90% and 99% confidence intervals for the regression parameters.</li>
<li>Verify that the standard errors reported by <code>summary</code> are just the square-roots of the diagonal of the variance-covariance matrix.</li>
<li>Bonus for linear regression aficionados: calculate the <span class="math inline">\(R^2\)</span> and adjusted <span class="math inline">\(R^2\)</span> using the functions <code>var</code> and <code>cor</code>, and the estimated residual standard error from the model fit.</li>
</ol>
</div>
<div id="prediction" class="section level3" number="9.3.4">
<h3><span class="header-section-number">9.3.4</span> Prediction</h3>
<p><strong>Basic prediction</strong> Once a model has been fitted, we can use it to make predictions about the expected value of the outcome variable for a given value of the predictor variable. So in terms of the basic equation above, for any value <span class="math inline">\(x_0\)</span> of the independent variable, we can predict the corresponding expexcted / average value of the dependent variable:
<span class="math display">\[
{\hat y}_0 = {\hat \beta}_0 + {\hat \beta}_1 \times x_0
\]</span>
So we just plug the estimated regression parameters into the regression equation.</p>
<p>In R, we can use the <code>predict</code>-function for this: we specify as input the fitted model, and the value or values of the independent variable for which we want to make a prediction. As an example, for our example model <code>lm1</code>, we want to predict the average hemoglobin level at 25%, 30%, 35%, … 55% PCV (covering the range of observed PCV values with a equidistant set of points). We can do this manually, using the function <code>c</code>, or we can take a shortcut by using the function <code>seq</code>:</p>
<div class="sourceCode" id="cb207"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb207-1"><a href="regression-linear.html#cb207-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">25</span>, <span class="at">to =</span> <span class="dv">55</span>, <span class="at">by =</span> <span class="dv">5</span>)</span>
<span id="cb207-2"><a href="regression-linear.html#cb207-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> x</span>
<span id="cb207-3"><a href="regression-linear.html#cb207-3" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="dv">25</span> <span class="dv">30</span> <span class="dv">35</span> <span class="dv">40</span> <span class="dv">45</span> <span class="dv">50</span> <span class="dv">55</span></span></code></pre></div>
<p>In order to make a prediction from the regression model, these values need to be stored as a column in a data frame, where the name of the column is exactly the same as the name of the predictor variable:</p>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb208-1"><a href="regression-linear.html#cb208-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> target <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">PCV =</span> x)</span>
<span id="cb208-2"><a href="regression-linear.html#cb208-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> target</span>
<span id="cb208-3"><a href="regression-linear.html#cb208-3" aria-hidden="true" tabindex="-1"></a>  PCV</span>
<span id="cb208-4"><a href="regression-linear.html#cb208-4" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span>  <span class="dv">25</span></span>
<span id="cb208-5"><a href="regression-linear.html#cb208-5" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span>  <span class="dv">30</span></span>
<span id="cb208-6"><a href="regression-linear.html#cb208-6" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span>  <span class="dv">35</span></span>
<span id="cb208-7"><a href="regression-linear.html#cb208-7" aria-hidden="true" tabindex="-1"></a><span class="dv">4</span>  <span class="dv">40</span></span>
<span id="cb208-8"><a href="regression-linear.html#cb208-8" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span>  <span class="dv">45</span></span>
<span id="cb208-9"><a href="regression-linear.html#cb208-9" aria-hidden="true" tabindex="-1"></a><span class="dv">6</span>  <span class="dv">50</span></span>
<span id="cb208-10"><a href="regression-linear.html#cb208-10" aria-hidden="true" tabindex="-1"></a><span class="dv">7</span>  <span class="dv">55</span></span></code></pre></div>
<p>Now we can pass the fitted model and the target data frame to <code>predict</code>, and we get a vector of predicted hemoglobin levels back:</p>
<div class="sourceCode" id="cb209"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb209-1"><a href="regression-linear.html#cb209-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> pr1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(lm1, <span class="at">newdata =</span> target)</span>
<span id="cb209-2"><a href="regression-linear.html#cb209-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> pr1</span>
<span id="cb209-3"><a href="regression-linear.html#cb209-3" aria-hidden="true" tabindex="-1"></a>       <span class="dv">1</span>        <span class="dv">2</span>        <span class="dv">3</span>        <span class="dv">4</span>        <span class="dv">5</span>        <span class="dv">6</span>        <span class="dv">7</span> </span>
<span id="cb209-4"><a href="regression-linear.html#cb209-4" aria-hidden="true" tabindex="-1"></a><span class="fl">10.70946</span> <span class="fl">11.73365</span> <span class="fl">12.75783</span> <span class="fl">13.78202</span> <span class="fl">14.80620</span> <span class="fl">15.83039</span> <span class="fl">16.85458</span> </span></code></pre></div>
<p>Now we have everything in place, the fitted model and the target data frame, so we can feed these to the function predict; we choose a confidence interval for the predicted mean, via argument interval, and this is what we get: a rectangular arrangement of numbers, just like a data frame, with one row per prediction, with the predicted value followed by the lower and upper end of the confidence interval.</p>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb210-1"><a href="regression-linear.html#cb210-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> pr1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(lm1, <span class="at">newdata =</span> target, <span class="at">interval =</span> <span class="st">&quot;confidence&quot;</span>)</span>
<span id="cb210-2"><a href="regression-linear.html#cb210-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> pr1</span>
<span id="cb210-3"><a href="regression-linear.html#cb210-3" aria-hidden="true" tabindex="-1"></a>       fit       lwr      upr</span>
<span id="cb210-4"><a href="regression-linear.html#cb210-4" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="fl">10.70946</span>  <span class="fl">8.666744</span> <span class="fl">12.75218</span></span>
<span id="cb210-5"><a href="regression-linear.html#cb210-5" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span> <span class="fl">11.73365</span> <span class="fl">10.178721</span> <span class="fl">13.28857</span></span>
<span id="cb210-6"><a href="regression-linear.html#cb210-6" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span> <span class="fl">12.75783</span> <span class="fl">11.625137</span> <span class="fl">13.89053</span></span>
<span id="cb210-7"><a href="regression-linear.html#cb210-7" aria-hidden="true" tabindex="-1"></a><span class="dv">4</span> <span class="fl">13.78202</span> <span class="fl">12.905485</span> <span class="fl">14.65855</span></span>
<span id="cb210-8"><a href="regression-linear.html#cb210-8" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span> <span class="fl">14.80620</span> <span class="fl">13.871471</span> <span class="fl">15.74094</span></span>
<span id="cb210-9"><a href="regression-linear.html#cb210-9" aria-hidden="true" tabindex="-1"></a><span class="dv">6</span> <span class="fl">15.83039</span> <span class="fl">14.565776</span> <span class="fl">17.09501</span></span>
<span id="cb210-10"><a href="regression-linear.html#cb210-10" aria-hidden="true" tabindex="-1"></a><span class="dv">7</span> <span class="fl">16.85458</span> <span class="fl">15.138513</span> <span class="fl">18.57064</span></span></code></pre></div>
<p>We can now plot or tabulate these predictions, as required.</p>
<p><strong>Prediction uncertainty</strong> Because the parameters of the model are estimated and come therefore with uncertainty (expressed as standard error or confidence interval, as seen above), the predictions made above are also uncertain. The <code>predict</code>-function can provide two different types of uncertainty intervals for the predicted estimates:</p>
<ul>
<li><em>confidence</em> intervals, which express the uncertainty about the location of the regression line (i.e. the expected / average value of the outcome),</li>
<li><em>prediction</em> intervals, which add the extra uncertainty of making an individual prediction around the expected mean.</li>
</ul>
<p>Confidence intervals capture the uncertainty about the exact location of the regression line, prediction intervals capture the uncertainty of the location of an individual observation.<a href="#fn48" class="footnote-ref" id="fnref48"><sup>48</sup></a></p>
<p>For our example, let’s add confidence intervals to the predictions. This produces a matrix with three columns, corresponding to the prediction, the lower limit of the (by default) 95% confidence interval, and the upper limit of the confidence interval:</p>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb211-1"><a href="regression-linear.html#cb211-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> pr2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(lm1, <span class="at">newdata =</span> target, <span class="at">interval =</span> <span class="st">&quot;confidence&quot;</span>)</span>
<span id="cb211-2"><a href="regression-linear.html#cb211-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> pr2</span>
<span id="cb211-3"><a href="regression-linear.html#cb211-3" aria-hidden="true" tabindex="-1"></a>       fit       lwr      upr</span>
<span id="cb211-4"><a href="regression-linear.html#cb211-4" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="fl">10.70946</span>  <span class="fl">8.666744</span> <span class="fl">12.75218</span></span>
<span id="cb211-5"><a href="regression-linear.html#cb211-5" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span> <span class="fl">11.73365</span> <span class="fl">10.178721</span> <span class="fl">13.28857</span></span>
<span id="cb211-6"><a href="regression-linear.html#cb211-6" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span> <span class="fl">12.75783</span> <span class="fl">11.625137</span> <span class="fl">13.89053</span></span>
<span id="cb211-7"><a href="regression-linear.html#cb211-7" aria-hidden="true" tabindex="-1"></a><span class="dv">4</span> <span class="fl">13.78202</span> <span class="fl">12.905485</span> <span class="fl">14.65855</span></span>
<span id="cb211-8"><a href="regression-linear.html#cb211-8" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span> <span class="fl">14.80620</span> <span class="fl">13.871471</span> <span class="fl">15.74094</span></span>
<span id="cb211-9"><a href="regression-linear.html#cb211-9" aria-hidden="true" tabindex="-1"></a><span class="dv">6</span> <span class="fl">15.83039</span> <span class="fl">14.565776</span> <span class="fl">17.09501</span></span>
<span id="cb211-10"><a href="regression-linear.html#cb211-10" aria-hidden="true" tabindex="-1"></a><span class="dv">7</span> <span class="fl">16.85458</span> <span class="fl">15.138513</span> <span class="fl">18.57064</span></span></code></pre></div>
<p>Note how the confidence intervals are narrower close the center of the data, where the regression line can be estimated more reliably, and wider at the ends of the data range, where the exact position of the regression line is less certain.</p>
<p>If we want to tabulate this, we can even combine this with the specified x-values and do some rounding:</p>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb212-1"><a href="regression-linear.html#cb212-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> tab_pred <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(target, <span class="fu">round</span>(pr2, <span class="dv">1</span>))</span>
<span id="cb212-2"><a href="regression-linear.html#cb212-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> tab_pred</span>
<span id="cb212-3"><a href="regression-linear.html#cb212-3" aria-hidden="true" tabindex="-1"></a>  PCV  fit  lwr  upr</span>
<span id="cb212-4"><a href="regression-linear.html#cb212-4" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span>  <span class="dv">25</span> <span class="fl">10.7</span>  <span class="fl">8.7</span> <span class="fl">12.8</span></span>
<span id="cb212-5"><a href="regression-linear.html#cb212-5" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span>  <span class="dv">30</span> <span class="fl">11.7</span> <span class="fl">10.2</span> <span class="fl">13.3</span></span>
<span id="cb212-6"><a href="regression-linear.html#cb212-6" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span>  <span class="dv">35</span> <span class="fl">12.8</span> <span class="fl">11.6</span> <span class="fl">13.9</span></span>
<span id="cb212-7"><a href="regression-linear.html#cb212-7" aria-hidden="true" tabindex="-1"></a><span class="dv">4</span>  <span class="dv">40</span> <span class="fl">13.8</span> <span class="fl">12.9</span> <span class="fl">14.7</span></span>
<span id="cb212-8"><a href="regression-linear.html#cb212-8" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span>  <span class="dv">45</span> <span class="fl">14.8</span> <span class="fl">13.9</span> <span class="fl">15.7</span></span>
<span id="cb212-9"><a href="regression-linear.html#cb212-9" aria-hidden="true" tabindex="-1"></a><span class="dv">6</span>  <span class="dv">50</span> <span class="fl">15.8</span> <span class="fl">14.6</span> <span class="fl">17.1</span></span>
<span id="cb212-10"><a href="regression-linear.html#cb212-10" aria-hidden="true" tabindex="-1"></a><span class="dv">7</span>  <span class="dv">55</span> <span class="fl">16.9</span> <span class="fl">15.1</span> <span class="fl">18.6</span></span></code></pre></div>
<p>And for a report, we might even want to run this through <code>pander</code>:</p>
<div class="sourceCode" id="cb213"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb213-1"><a href="regression-linear.html#cb213-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">library</span>(pander)</span>
<span id="cb213-2"><a href="regression-linear.html#cb213-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">pander</span>(tab_pred)</span></code></pre></div>
<table style="width:38%;">
<colgroup>
<col width="8%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">PCV</th>
<th align="center">fit</th>
<th align="center">lwr</th>
<th align="center">upr</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">25</td>
<td align="center">10.7</td>
<td align="center">8.7</td>
<td align="center">12.8</td>
</tr>
<tr class="even">
<td align="center">30</td>
<td align="center">11.7</td>
<td align="center">10.2</td>
<td align="center">13.3</td>
</tr>
<tr class="odd">
<td align="center">35</td>
<td align="center">12.8</td>
<td align="center">11.6</td>
<td align="center">13.9</td>
</tr>
<tr class="even">
<td align="center">40</td>
<td align="center">13.8</td>
<td align="center">12.9</td>
<td align="center">14.7</td>
</tr>
<tr class="odd">
<td align="center">45</td>
<td align="center">14.8</td>
<td align="center">13.9</td>
<td align="center">15.7</td>
</tr>
<tr class="even">
<td align="center">50</td>
<td align="center">15.8</td>
<td align="center">14.6</td>
<td align="center">17.1</td>
</tr>
<tr class="odd">
<td align="center">55</td>
<td align="center">16.9</td>
<td align="center">15.1</td>
<td align="center">18.6</td>
</tr>
</tbody>
</table>
<p><strong>Default prediction</strong> As a variation of this approach, we can also call <code>predict</code> without explicitly specifying target values for the predictor. In this case, R will use the observed values of the predictor variable in the data set used for fitting the model (so <code>hemoglobin</code> in our example), and return predictions for these locations:</p>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb214-1"><a href="regression-linear.html#cb214-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">predict</span>(lm1)</span>
<span id="cb214-2"><a href="regression-linear.html#cb214-2" aria-hidden="true" tabindex="-1"></a>       <span class="dv">1</span>        <span class="dv">2</span>        <span class="dv">3</span>        <span class="dv">4</span>        <span class="dv">5</span>        <span class="dv">6</span>        <span class="dv">7</span>        <span class="dv">8</span>        <span class="dv">9</span>       <span class="dv">10</span>       <span class="dv">11</span> </span>
<span id="cb214-3"><a href="regression-linear.html#cb214-3" aria-hidden="true" tabindex="-1"></a><span class="fl">12.75783</span> <span class="fl">14.80620</span> <span class="fl">15.21588</span> <span class="fl">15.83039</span> <span class="fl">11.93848</span> <span class="fl">11.73365</span> <span class="fl">10.70946</span> <span class="fl">12.34816</span> <span class="fl">12.75783</span> <span class="fl">13.78202</span> <span class="fl">14.80620</span> </span>
<span id="cb214-4"><a href="regression-linear.html#cb214-4" aria-hidden="true" tabindex="-1"></a>      <span class="dv">12</span>       <span class="dv">13</span>       <span class="dv">14</span>       <span class="dv">15</span>       <span class="dv">16</span>       <span class="dv">17</span>       <span class="dv">18</span>       <span class="dv">19</span>       <span class="dv">20</span> </span>
<span id="cb214-5"><a href="regression-linear.html#cb214-5" aria-hidden="true" tabindex="-1"></a><span class="fl">15.21588</span> <span class="fl">15.62555</span> <span class="fl">14.19169</span> <span class="fl">13.78202</span> <span class="fl">15.83039</span> <span class="fl">15.01104</span> <span class="fl">16.85458</span> <span class="fl">14.19169</span> <span class="fl">15.01104</span> </span></code></pre></div>
<p>Unless you have an incredibly well designed study, this is usually not very helpful.</p>
<p><strong>Exercises:</strong></p>
<ol style="list-style-type: decimal">
<li>For the same ages as above, make predictions using <code>interval="confidence"</code> and <code>interval="prediction</code> and compare the results.</li>
<li>Make the same predictions on the observed predictor values as the “short” form <code>predict(lm1)</code> produces, but by explicitly specifying a target via <code>newdata</code>; include a confidence interval, and build a nice prediction table that combines the target values, the predicted values and the confidence intervals.</li>
</ol>
</div>
<div id="diagnostics" class="section level3" number="9.3.5">
<h3><span class="header-section-number">9.3.5</span> Diagnostics</h3>
<p>UNDER CONSTRUCTION</p>
</div>
<div id="binary-predictor-and-dummy-coding" class="section level3" number="9.3.6">
<h3><span class="header-section-number">9.3.6</span> Binary predictor and dummy coding</h3>
<p><strong>Dummy coding</strong> We can also use a binary variable as predictor in a simple linear regression model, by using <em>dummy coding</em>: for any variable with two levels, we can generate a <em>dummy variable</em> which haz value zero for one level (the <em>reference level</em>) and one for the other level (sometimes called <em>exposure level</em>). For such a dummy variable <span class="math inline">\(x_{dummy}\)</span>, we can write down the same regression equation as before:
<span class="math display">\[
y = \beta_0 + \beta_1 \times x_{dummy} + \epsilon
\]</span>
Note that we can get only two different variants of this equation:
[</p>
y = {
<span class="math display">\[\begin{array}{lr} \beta_0 +          \epsilon &amp; \mathrm{iff} \,\, x_{dummy} = 0 \\
                             \beta_0 + \beta_1 + \epsilon &amp; \mathrm{iff} \,\,x_{dummy} = 1 
           \end{array}\]</span>
<p>.</p>
<p>]
We generally do not have to do our own dummy coding in R - this is one of the things that the formula notation does for us. However, we still need to understand the concept to understand the output that is generated.</p>
<p><strong>Dummy coding in R</strong> Let’s look at our example, which includes menopausal status:</p>
<div class="sourceCode" id="cb215"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb215-1"><a href="regression-linear.html#cb215-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> hemoglobin<span class="sc">$</span>Menopause</span>
<span id="cb215-2"><a href="regression-linear.html#cb215-2" aria-hidden="true" tabindex="-1"></a> [<span class="dv">1</span>] No  No  No  No  No  No  No  No  No  Yes No  Yes Yes Yes Yes Yes Yes Yes Yes Yes</span>
<span id="cb215-3"><a href="regression-linear.html#cb215-3" aria-hidden="true" tabindex="-1"></a>Levels<span class="sc">:</span> No Yes</span></code></pre></div>
<p>We see that <code>Menopause</code> is a factor variable with two levels, <code>No</code> (pre-menopausal) and <code>Yes</code> (post-menopausal). If we want to model the hemoglobin level as a function of menopausal status, we can simply adapt the model formula:</p>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb216-1"><a href="regression-linear.html#cb216-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> lm2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Hb <span class="sc">~</span> Menopause, hemoglobin)</span>
<span id="cb216-2"><a href="regression-linear.html#cb216-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">summary</span>(lm2)</span>
<span id="cb216-3"><a href="regression-linear.html#cb216-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb216-4"><a href="regression-linear.html#cb216-4" aria-hidden="true" tabindex="-1"></a>Call<span class="sc">:</span></span>
<span id="cb216-5"><a href="regression-linear.html#cb216-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(<span class="at">formula =</span> Hb <span class="sc">~</span> Menopause, <span class="at">data =</span> hemoglobin)</span>
<span id="cb216-6"><a href="regression-linear.html#cb216-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb216-7"><a href="regression-linear.html#cb216-7" aria-hidden="true" tabindex="-1"></a>Residuals<span class="sc">:</span></span>
<span id="cb216-8"><a href="regression-linear.html#cb216-8" aria-hidden="true" tabindex="-1"></a>   Min     1Q Median     3Q    Max </span>
<span id="cb216-9"><a href="regression-linear.html#cb216-9" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="fl">2.650</span> <span class="sc">-</span><span class="fl">1.250</span>  <span class="fl">0.280</span>  <span class="fl">0.865</span>  <span class="fl">2.850</span> </span>
<span id="cb216-10"><a href="regression-linear.html#cb216-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb216-11"><a href="regression-linear.html#cb216-11" aria-hidden="true" tabindex="-1"></a>Coefficients<span class="sc">:</span></span>
<span id="cb216-12"><a href="regression-linear.html#cb216-12" aria-hidden="true" tabindex="-1"></a>             Estimate Std. Error t value <span class="fu">Pr</span>(<span class="sc">&gt;</span><span class="er">|</span>t<span class="sc">|</span>)    </span>
<span id="cb216-13"><a href="regression-linear.html#cb216-13" aria-hidden="true" tabindex="-1"></a>(Intercept)   <span class="fl">12.2500</span>     <span class="fl">0.4695</span>  <span class="fl">26.093</span> <span class="fl">9.36e-16</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb216-14"><a href="regression-linear.html#cb216-14" aria-hidden="true" tabindex="-1"></a>MenopauseYes   <span class="fl">3.7400</span>     <span class="fl">0.6639</span>   <span class="fl">5.633</span> <span class="fl">2.41e-05</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb216-15"><a href="regression-linear.html#cb216-15" aria-hidden="true" tabindex="-1"></a><span class="sc">---</span></span>
<span id="cb216-16"><a href="regression-linear.html#cb216-16" aria-hidden="true" tabindex="-1"></a>Signif. codes<span class="sc">:</span>  <span class="dv">0</span> <span class="st">&#39;***&#39;</span> <span class="fl">0.001</span> <span class="st">&#39;**&#39;</span> <span class="fl">0.01</span> <span class="st">&#39;*&#39;</span> <span class="fl">0.05</span> <span class="st">&#39;.&#39;</span> <span class="fl">0.1</span> <span class="st">&#39; &#39;</span> <span class="dv">1</span></span>
<span id="cb216-17"><a href="regression-linear.html#cb216-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb216-18"><a href="regression-linear.html#cb216-18" aria-hidden="true" tabindex="-1"></a>Residual standard error<span class="sc">:</span> <span class="fl">1.485</span> on <span class="dv">18</span> degrees of freedom</span>
<span id="cb216-19"><a href="regression-linear.html#cb216-19" aria-hidden="true" tabindex="-1"></a>Multiple R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.6381</span>,    Adjusted R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.6179</span> </span>
<span id="cb216-20"><a href="regression-linear.html#cb216-20" aria-hidden="true" tabindex="-1"></a>F<span class="sc">-</span>statistic<span class="sc">:</span> <span class="fl">31.73</span> on <span class="dv">1</span> and <span class="dv">18</span> DF,  p<span class="sc">-</span>value<span class="sc">:</span> <span class="fl">2.41e-05</span></span></code></pre></div>
<p>We see the same overall <code>summary</code>-output as above, including information on the function call and residuals, the regression table, and the extra model statistics. The only place where we realize that we have dependent variable that is a factor is in the regression table:</p>
<pre><code>             Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)     12.20      0.469   26.10 9.36e-16
MenopauseYes     3.74      0.664    5.63 2.41e-05</code></pre>
<p>The first row with the <code>(Intercept)</code> has the same structure as before, but the second row shows not only the name of the variable (<code>Menopause</code>), but the variable name with the exposure level added to it: <code>MenopauseYes</code>. This shows us that the parameter in this row (<span class="math inline">\({\hat \beta}=3.74\)</span>) refers to a dummy variable, and specifically, a dummy variable which is equal to one when the variable <code>Menopause</code> is equal to <code>Yes</code>. The reference level on the other is not shown - we have to understand from our inspection of the data that that is the complementary level <code>No</code>.</p>
<p><strong>Changing the reference level</strong> By default, R will use the first level of a factor variable as the reference level.<a href="#fn49" class="footnote-ref" id="fnref49"><sup>49</sup></a> We can change the parametrization of the regression model by changing the order of factor levels using the function <code>relevel</code>:</p>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb218-1"><a href="regression-linear.html#cb218-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> hemo2 <span class="ot">&lt;-</span> hemoglobin</span>
<span id="cb218-2"><a href="regression-linear.html#cb218-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> hemo2<span class="sc">$</span>Menopause <span class="ot">&lt;-</span> <span class="fu">relevel</span>(hemo2<span class="sc">$</span>Menopause, <span class="at">ref =</span> <span class="st">&quot;Yes&quot;</span>)</span>
<span id="cb218-3"><a href="regression-linear.html#cb218-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> hemo2<span class="sc">$</span>Menopause</span>
<span id="cb218-4"><a href="regression-linear.html#cb218-4" aria-hidden="true" tabindex="-1"></a> [<span class="dv">1</span>] No  No  No  No  No  No  No  No  No  Yes No  Yes Yes Yes Yes Yes Yes Yes Yes Yes</span>
<span id="cb218-5"><a href="regression-linear.html#cb218-5" aria-hidden="true" tabindex="-1"></a>Levels<span class="sc">:</span> Yes No</span></code></pre></div>
<p><code>Yes</code> is now the first factor level in the modified data set; if we re-fit the model for the modified data, we get this:</p>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb219-1"><a href="regression-linear.html#cb219-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">summary</span>(<span class="fu">lm</span>(Hb <span class="sc">~</span> Menopause, hemo2))</span>
<span id="cb219-2"><a href="regression-linear.html#cb219-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb219-3"><a href="regression-linear.html#cb219-3" aria-hidden="true" tabindex="-1"></a>Call<span class="sc">:</span></span>
<span id="cb219-4"><a href="regression-linear.html#cb219-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(<span class="at">formula =</span> Hb <span class="sc">~</span> Menopause, <span class="at">data =</span> hemo2)</span>
<span id="cb219-5"><a href="regression-linear.html#cb219-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb219-6"><a href="regression-linear.html#cb219-6" aria-hidden="true" tabindex="-1"></a>Residuals<span class="sc">:</span></span>
<span id="cb219-7"><a href="regression-linear.html#cb219-7" aria-hidden="true" tabindex="-1"></a>   Min     1Q Median     3Q    Max </span>
<span id="cb219-8"><a href="regression-linear.html#cb219-8" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="fl">2.650</span> <span class="sc">-</span><span class="fl">1.250</span>  <span class="fl">0.280</span>  <span class="fl">0.865</span>  <span class="fl">2.850</span> </span>
<span id="cb219-9"><a href="regression-linear.html#cb219-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb219-10"><a href="regression-linear.html#cb219-10" aria-hidden="true" tabindex="-1"></a>Coefficients<span class="sc">:</span></span>
<span id="cb219-11"><a href="regression-linear.html#cb219-11" aria-hidden="true" tabindex="-1"></a>            Estimate Std. Error t value <span class="fu">Pr</span>(<span class="sc">&gt;</span><span class="er">|</span>t<span class="sc">|</span>)    </span>
<span id="cb219-12"><a href="regression-linear.html#cb219-12" aria-hidden="true" tabindex="-1"></a>(Intercept)  <span class="fl">15.9900</span>     <span class="fl">0.4695</span>  <span class="fl">34.059</span>  <span class="sc">&lt;</span> <span class="fl">2e-16</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb219-13"><a href="regression-linear.html#cb219-13" aria-hidden="true" tabindex="-1"></a>MenopauseNo  <span class="sc">-</span><span class="fl">3.7400</span>     <span class="fl">0.6639</span>  <span class="sc">-</span><span class="fl">5.633</span> <span class="fl">2.41e-05</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb219-14"><a href="regression-linear.html#cb219-14" aria-hidden="true" tabindex="-1"></a><span class="sc">---</span></span>
<span id="cb219-15"><a href="regression-linear.html#cb219-15" aria-hidden="true" tabindex="-1"></a>Signif. codes<span class="sc">:</span>  <span class="dv">0</span> <span class="st">&#39;***&#39;</span> <span class="fl">0.001</span> <span class="st">&#39;**&#39;</span> <span class="fl">0.01</span> <span class="st">&#39;*&#39;</span> <span class="fl">0.05</span> <span class="st">&#39;.&#39;</span> <span class="fl">0.1</span> <span class="st">&#39; &#39;</span> <span class="dv">1</span></span>
<span id="cb219-16"><a href="regression-linear.html#cb219-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb219-17"><a href="regression-linear.html#cb219-17" aria-hidden="true" tabindex="-1"></a>Residual standard error<span class="sc">:</span> <span class="fl">1.485</span> on <span class="dv">18</span> degrees of freedom</span>
<span id="cb219-18"><a href="regression-linear.html#cb219-18" aria-hidden="true" tabindex="-1"></a>Multiple R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.6381</span>,    Adjusted R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.6179</span> </span>
<span id="cb219-19"><a href="regression-linear.html#cb219-19" aria-hidden="true" tabindex="-1"></a>F<span class="sc">-</span>statistic<span class="sc">:</span> <span class="fl">31.73</span> on <span class="dv">1</span> and <span class="dv">18</span> DF,  p<span class="sc">-</span>value<span class="sc">:</span> <span class="fl">2.41e-05</span></span></code></pre></div>
<p>Looking at the regression table, we see that this has worked as intended: the second row now has the name <code>MenopauseNo</code>, so the new exposure level is now <code>No</code> and the reference level is <code>Yes</code>. However, it is at least as instructive to check what has not changed:</p>
<ul>
<li>looking at the regression table again, we find that the slope estimate for <code>MenopauseNo</code> is just the negative value for the slope estimate for <code>MenopauseYes</code>; and apart from the sign, the estimate, standard error, t-statistic and p-value are all the same. The intercept has a different estimate, but the same standard error.</li>
<li>looking at the residuals and the model summary statistics like residual standard error, <span class="math inline">\(R^2\)</span> etc., we find them to be <em>identical</em>. This is of course not an accident - the re-parametrization we have performed changes the interpretation of the parameters (that was the actual point to start with), but not the model fit: the old and the new model have the same predictions and the same residuals, and are indeed the same model, apart from the parameter interpretation.</li>
</ul>
<p><strong>Prediction</strong> This works as before, using the <code>predict</code>-function. Note however that we only get two different estimates, corresponding to the two forms of the dummy-coded regression equation:</p>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="regression-linear.html#cb220-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">predict</span>(lm2)</span>
<span id="cb220-2"><a href="regression-linear.html#cb220-2" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span>     <span class="dv">2</span>     <span class="dv">3</span>     <span class="dv">4</span>     <span class="dv">5</span>     <span class="dv">6</span>     <span class="dv">7</span>     <span class="dv">8</span>     <span class="dv">9</span>    <span class="dv">10</span>    <span class="dv">11</span>    <span class="dv">12</span>    <span class="dv">13</span>    <span class="dv">14</span>    <span class="dv">15</span>    <span class="dv">16</span> </span>
<span id="cb220-3"><a href="regression-linear.html#cb220-3" aria-hidden="true" tabindex="-1"></a><span class="fl">12.25</span> <span class="fl">12.25</span> <span class="fl">12.25</span> <span class="fl">12.25</span> <span class="fl">12.25</span> <span class="fl">12.25</span> <span class="fl">12.25</span> <span class="fl">12.25</span> <span class="fl">12.25</span> <span class="fl">15.99</span> <span class="fl">12.25</span> <span class="fl">15.99</span> <span class="fl">15.99</span> <span class="fl">15.99</span> <span class="fl">15.99</span> <span class="fl">15.99</span> </span>
<span id="cb220-4"><a href="regression-linear.html#cb220-4" aria-hidden="true" tabindex="-1"></a>   <span class="dv">17</span>    <span class="dv">18</span>    <span class="dv">19</span>    <span class="dv">20</span> </span>
<span id="cb220-5"><a href="regression-linear.html#cb220-5" aria-hidden="true" tabindex="-1"></a><span class="fl">15.99</span> <span class="fl">15.99</span> <span class="fl">15.99</span> <span class="fl">15.99</span> </span></code></pre></div>
<p>And it turns out that these two distinct replicated values are just the average hemoglobin levels in each group. So for real application, having a simple linear regression model with one binary predictor is not especially interesting - that comes when we have more than two levels in a discrete predictor and / or multiple predictor variables in the model (see also Exercise 1 below).</p>
<p><strong>Exercises:</strong></p>
<ol style="list-style-type: decimal">
<li><p>A linear model with just one binary predictor like here is mathematically equivalent to a Student t-test:</p>
<div class="sourceCode" id="cb221"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb221-1"><a href="regression-linear.html#cb221-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">t.test</span>(Hb <span class="sc">~</span> Menopause, <span class="at">data =</span> hemoglobin, <span class="at">var.equal =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>Run this test in R, and identify all points where the test output and the regression summary agree.</p></li>
<li><p>For the linear model with the re-leveled menopausal variable, can you write the complete process (releveling the factor variable, fitting the linear model, extarting the summary) in one row of R code (e.g. as nested function calls or as pipeline)?</p></li>
</ol>
</div>
<div id="nicer-regression-tables" class="section level3" number="9.3.7">
<h3><span class="header-section-number">9.3.7</span> Nicer regression tables</h3>
<p>We can use <code>pander</code> also for regression models. Directly applied to the fitted model, we get the regression table:</p>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="regression-linear.html#cb222-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">pander</span>(lm1)</span></code></pre></div>
<table style="width:88%;">
<caption>Fitting linear model: Hb ~ PCV</caption>
<colgroup>
<col width="25%" />
<col width="15%" />
<col width="18%" />
<col width="13%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">t value</th>
<th align="center">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">5.589</td>
<td align="center">2.245</td>
<td align="center">2.489</td>
<td align="center">0.02282</td>
</tr>
<tr class="even">
<td align="center"><strong>PCV</strong></td>
<td align="center">0.2048</td>
<td align="center">0.05301</td>
<td align="center">3.864</td>
<td align="center">0.001136</td>
</tr>
</tbody>
</table>
<p>We can also apply <code>pander</code> to the summary of a fitted model, which shows both the regression table and some model statistics:</p>
<div class="sourceCode" id="cb223"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb223-1"><a href="regression-linear.html#cb223-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">pander</span>(<span class="fu">summary</span>(lm1))</span></code></pre></div>
<table style="width:88%;">
<colgroup>
<col width="25%" />
<col width="15%" />
<col width="18%" />
<col width="13%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">t value</th>
<th align="center">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">5.589</td>
<td align="center">2.245</td>
<td align="center">2.489</td>
<td align="center">0.02282</td>
</tr>
<tr class="even">
<td align="center"><strong>PCV</strong></td>
<td align="center">0.2048</td>
<td align="center">0.05301</td>
<td align="center">3.864</td>
<td align="center">0.001136</td>
</tr>
</tbody>
</table>
<table style="width:88%;">
<caption>Fitting linear model: Hb ~ PCV</caption>
<colgroup>
<col width="20%" />
<col width="30%" />
<col width="12%" />
<col width="23%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Observations</th>
<th align="center">Residual Std. Error</th>
<th align="center"><span class="math inline">\(R^2\)</span></th>
<th align="center">Adjusted <span class="math inline">\(R^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">20</td>
<td align="center">1.824</td>
<td align="center">0.4534</td>
<td align="center">0.4231</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="multiple-linear-regression" class="section level2" number="9.4">
<h2><span class="header-section-number">9.4</span> Multiple linear regression</h2>
<div id="multiple-predictors" class="section level3" number="9.4.1">
<h3><span class="header-section-number">9.4.1</span> Multiple predictors</h3>
<p>In epidemiology, the final model in an analysis will rarely be a simple regression model with only one predictor: generally, there will be an attempt to adjust the estimated association between the main exposure and an outcome of interest for confounding by including the potential confounding variables as additional predictors in the model.</p>
<p>In our example, we can consider age and menopausal status as such potential confounders. Including them in the model just requires adding them to the right hand side of the model formula</p>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="regression-linear.html#cb224-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> lm3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Hb <span class="sc">~</span> PCV <span class="sc">+</span> Age <span class="sc">+</span> Menopause, <span class="at">data =</span> hemo)</span>
<span id="cb224-2"><a href="regression-linear.html#cb224-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">summary</span>(lm3)</span>
<span id="cb224-3"><a href="regression-linear.html#cb224-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb224-4"><a href="regression-linear.html#cb224-4" aria-hidden="true" tabindex="-1"></a>Call<span class="sc">:</span></span>
<span id="cb224-5"><a href="regression-linear.html#cb224-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(<span class="at">formula =</span> Hb <span class="sc">~</span> PCV <span class="sc">+</span> Age <span class="sc">+</span> Menopause, <span class="at">data =</span> hemo)</span>
<span id="cb224-6"><a href="regression-linear.html#cb224-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb224-7"><a href="regression-linear.html#cb224-7" aria-hidden="true" tabindex="-1"></a>Residuals<span class="sc">:</span></span>
<span id="cb224-8"><a href="regression-linear.html#cb224-8" aria-hidden="true" tabindex="-1"></a>    Min      1Q  Median      3Q     Max </span>
<span id="cb224-9"><a href="regression-linear.html#cb224-9" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="fl">1.6011</span> <span class="sc">-</span><span class="fl">0.6784</span>  <span class="fl">0.2155</span>  <span class="fl">0.5463</span>  <span class="fl">1.7589</span> </span>
<span id="cb224-10"><a href="regression-linear.html#cb224-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb224-11"><a href="regression-linear.html#cb224-11" aria-hidden="true" tabindex="-1"></a>Coefficients<span class="sc">:</span></span>
<span id="cb224-12"><a href="regression-linear.html#cb224-12" aria-hidden="true" tabindex="-1"></a>             Estimate Std. Error t value <span class="fu">Pr</span>(<span class="sc">&gt;</span><span class="er">|</span>t<span class="sc">|</span>)   </span>
<span id="cb224-13"><a href="regression-linear.html#cb224-13" aria-hidden="true" tabindex="-1"></a>(Intercept)   <span class="fl">5.21455</span>    <span class="fl">1.57182</span>   <span class="fl">3.318</span>  <span class="fl">0.00436</span> <span class="sc">**</span></span>
<span id="cb224-14"><a href="regression-linear.html#cb224-14" aria-hidden="true" tabindex="-1"></a>PCV           <span class="fl">0.09734</span>    <span class="fl">0.03459</span>   <span class="fl">2.815</span>  <span class="fl">0.01246</span> <span class="sc">*</span> </span>
<span id="cb224-15"><a href="regression-linear.html#cb224-15" aria-hidden="true" tabindex="-1"></a>Age           <span class="fl">0.11103</span>    <span class="fl">0.03033</span>   <span class="fl">3.661</span>  <span class="fl">0.00211</span> <span class="sc">**</span></span>
<span id="cb224-16"><a href="regression-linear.html#cb224-16" aria-hidden="true" tabindex="-1"></a>MenopauseYes <span class="sc">-</span><span class="fl">0.02407</span>    <span class="fl">0.95401</span>  <span class="sc">-</span><span class="fl">0.025</span>  <span class="fl">0.98018</span>   </span>
<span id="cb224-17"><a href="regression-linear.html#cb224-17" aria-hidden="true" tabindex="-1"></a><span class="sc">---</span></span>
<span id="cb224-18"><a href="regression-linear.html#cb224-18" aria-hidden="true" tabindex="-1"></a>Signif. codes<span class="sc">:</span>  <span class="dv">0</span> <span class="st">&#39;***&#39;</span> <span class="fl">0.001</span> <span class="st">&#39;**&#39;</span> <span class="fl">0.01</span> <span class="st">&#39;*&#39;</span> <span class="fl">0.05</span> <span class="st">&#39;.&#39;</span> <span class="fl">0.1</span> <span class="st">&#39; &#39;</span> <span class="dv">1</span></span>
<span id="cb224-19"><a href="regression-linear.html#cb224-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb224-20"><a href="regression-linear.html#cb224-20" aria-hidden="true" tabindex="-1"></a>Residual standard error<span class="sc">:</span> <span class="fl">1.01</span> on <span class="dv">16</span> degrees of freedom</span>
<span id="cb224-21"><a href="regression-linear.html#cb224-21" aria-hidden="true" tabindex="-1"></a>Multiple R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.8512</span>,    Adjusted R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.8233</span> </span>
<span id="cb224-22"><a href="regression-linear.html#cb224-22" aria-hidden="true" tabindex="-1"></a>F<span class="sc">-</span>statistic<span class="sc">:</span> <span class="fl">30.51</span> on <span class="dv">3</span> and <span class="dv">16</span> DF,  p<span class="sc">-</span>value<span class="sc">:</span> <span class="fl">7.464e-07</span></span></code></pre></div>
<p>Call- and residual information still have the same appearance, but the regression table has now additional rows for the new predictors. Compared to the unadjusted model above, we see that the effect size (<span class="math inline">\({\hat \beta}\)</span>, slope) for the exposure PCV has been reduced by half (ca. 0.10 vs 0.20), but is still statistically significantly different from zero (<span class="math inline">\(p=0.02\)</span>). We also see that among the covariates, age is robustly and statistically significantly associated with hemoglobin level: an age increase by one year is associated with a comparable increase of the outcome as an increase of the PCV-level by 1%. Interestingly, menopausal status is not statistically significantly associated with hemoglobin level in the adjusted model, with <span class="math inline">\(p=0.98\)</span> and a very small effect size - it seems that the association we saw above for <code>lm2</code> was due to confounding by age.</p>
<p>Note that the adjusted model explains most of the variability in the data, with an adjusted <span class="math inline">\(R^2=82\%\)</span>. We also see that now, the null hypothesis of the F-test can be interesting: namely that the model as a whole (i.e. including all three predictors) does not fit the data better than a simple constant mean model (i.e. that all three slope parameters are zero at the same time). We can reject this hypothesis at <span class="math inline">\(p=7.5E-7\)</span>: we have cealry stronger evidence against the joint null hypothesis of the F-test than for the per-parameter null hypothesis for each of the parameters in the regression table.</p>
<p>Note that the other helper functions we have discussed (<code>confint</code>, <code>predict</code> as well as <code>plot</code>) still work in the same manner.<a href="#fn50" class="footnote-ref" id="fnref50"><sup>50</sup></a></p>
</div>
<div id="categorical-predictors-with-2-levels" class="section level3" number="9.4.2">
<h3><span class="header-section-number">9.4.2</span> Categorical predictors with <span class="math inline">\(&gt;\)</span> 2 levels</h3>
<p>Another way of adding more parameters than just intercept and slope to a regression models is by using a discrete predictor variable with more than two levels: we still get to choose one level as reference level, but then we have to add one dummy variable for each remaining level of the factor.</p>
<p>For our example, we may want to categorize age by splitting to into three approximately equally big groups.<a href="#fn51" class="footnote-ref" id="fnref51"><sup>51</sup></a> We can use the function <code>quantile</code> to identify reasonable categories:</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb225-1"><a href="regression-linear.html#cb225-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">quantile</span>(hemoglobin<span class="sc">$</span>Age, <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.33</span>, <span class="fl">0.67</span>))</span>
<span id="cb225-2"><a href="regression-linear.html#cb225-2" aria-hidden="true" tabindex="-1"></a>  <span class="dv">33</span><span class="sc">%   67%</span> </span>
<span id="cb225-3"><a href="regression-linear.html#cb225-3" aria-hidden="true" tabindex="-1"></a><span class="fl">32.81</span> <span class="fl">54.73</span> </span></code></pre></div>
<p>So we could e.g. split the data at 35 and 55 years of age (to nicer limits):</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb226-1"><a href="regression-linear.html#cb226-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> hemoglobin <span class="ot">&lt;-</span> <span class="fu">transform</span>(hemoglobin, <span class="at">Age_gr =</span> <span class="fu">cut</span>(Age, <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">33</span>, <span class="dv">55</span>, <span class="dv">99</span>)))</span>
<span id="cb226-2"><a href="regression-linear.html#cb226-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">table</span>(hemoglobin<span class="sc">$</span>Age_gr)</span>
<span id="cb226-3"><a href="regression-linear.html#cb226-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb226-4"><a href="regression-linear.html#cb226-4" aria-hidden="true" tabindex="-1"></a> (<span class="dv">0</span>,<span class="dv">33</span>] (<span class="dv">33</span>,<span class="dv">55</span>] (<span class="dv">55</span>,<span class="dv">99</span>] </span>
<span id="cb226-5"><a href="regression-linear.html#cb226-5" aria-hidden="true" tabindex="-1"></a>      <span class="dv">7</span>       <span class="dv">7</span>       <span class="dv">6</span> </span></code></pre></div>
<p>That is nicely balanced, so this should make a reasonable predictor:</p>
<div class="sourceCode" id="cb227"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb227-1"><a href="regression-linear.html#cb227-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> lm4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Hb <span class="sc">~</span> Age_gr, <span class="at">data =</span> hemoglobin)</span>
<span id="cb227-2"><a href="regression-linear.html#cb227-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">summary</span>(lm4)</span>
<span id="cb227-3"><a href="regression-linear.html#cb227-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb227-4"><a href="regression-linear.html#cb227-4" aria-hidden="true" tabindex="-1"></a>Call<span class="sc">:</span></span>
<span id="cb227-5"><a href="regression-linear.html#cb227-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(<span class="at">formula =</span> Hb <span class="sc">~</span> Age_gr, <span class="at">data =</span> hemoglobin)</span>
<span id="cb227-6"><a href="regression-linear.html#cb227-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb227-7"><a href="regression-linear.html#cb227-7" aria-hidden="true" tabindex="-1"></a>Residuals<span class="sc">:</span></span>
<span id="cb227-8"><a href="regression-linear.html#cb227-8" aria-hidden="true" tabindex="-1"></a>    Min      1Q  Median      3Q     Max </span>
<span id="cb227-9"><a href="regression-linear.html#cb227-9" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="fl">2.0286</span> <span class="sc">-</span><span class="fl">0.9071</span> <span class="sc">-</span><span class="fl">0.0500</span>  <span class="fl">0.6536</span>  <span class="fl">2.3714</span> </span>
<span id="cb227-10"><a href="regression-linear.html#cb227-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb227-11"><a href="regression-linear.html#cb227-11" aria-hidden="true" tabindex="-1"></a>Coefficients<span class="sc">:</span></span>
<span id="cb227-12"><a href="regression-linear.html#cb227-12" aria-hidden="true" tabindex="-1"></a>              Estimate Std. Error t value <span class="fu">Pr</span>(<span class="sc">&gt;</span><span class="er">|</span>t<span class="sc">|</span>)    </span>
<span id="cb227-13"><a href="regression-linear.html#cb227-13" aria-hidden="true" tabindex="-1"></a>(Intercept)    <span class="fl">11.6286</span>     <span class="fl">0.4879</span>  <span class="fl">23.836</span> <span class="fl">1.67e-14</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb227-14"><a href="regression-linear.html#cb227-14" aria-hidden="true" tabindex="-1"></a><span class="fu">Age_gr</span>(<span class="dv">33</span>,<span class="dv">55</span>]   <span class="fl">2.8571</span>     <span class="fl">0.6899</span>   <span class="fl">4.141</span> <span class="fl">0.000683</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb227-15"><a href="regression-linear.html#cb227-15" aria-hidden="true" tabindex="-1"></a><span class="fu">Age_gr</span>(<span class="dv">55</span>,<span class="dv">99</span>]   <span class="fl">4.9714</span>     <span class="fl">0.7181</span>   <span class="fl">6.923</span> <span class="fl">2.46e-06</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb227-16"><a href="regression-linear.html#cb227-16" aria-hidden="true" tabindex="-1"></a><span class="sc">---</span></span>
<span id="cb227-17"><a href="regression-linear.html#cb227-17" aria-hidden="true" tabindex="-1"></a>Signif. codes<span class="sc">:</span>  <span class="dv">0</span> <span class="st">&#39;***&#39;</span> <span class="fl">0.001</span> <span class="st">&#39;**&#39;</span> <span class="fl">0.01</span> <span class="st">&#39;*&#39;</span> <span class="fl">0.05</span> <span class="st">&#39;.&#39;</span> <span class="fl">0.1</span> <span class="st">&#39; &#39;</span> <span class="dv">1</span></span>
<span id="cb227-18"><a href="regression-linear.html#cb227-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb227-19"><a href="regression-linear.html#cb227-19" aria-hidden="true" tabindex="-1"></a>Residual standard error<span class="sc">:</span> <span class="fl">1.291</span> on <span class="dv">17</span> degrees of freedom</span>
<span id="cb227-20"><a href="regression-linear.html#cb227-20" aria-hidden="true" tabindex="-1"></a>Multiple R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.7416</span>,    Adjusted R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.7112</span> </span>
<span id="cb227-21"><a href="regression-linear.html#cb227-21" aria-hidden="true" tabindex="-1"></a>F<span class="sc">-</span>statistic<span class="sc">:</span>  <span class="fl">24.4</span> on <span class="dv">2</span> and <span class="dv">17</span> DF,  p<span class="sc">-</span>value<span class="sc">:</span> <span class="fl">1.01e-05</span></span></code></pre></div>
<p>As before, this only changes the shape of the regression table:</p>
<pre><code>              Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)      11.60      0.488   23.80 1.67e-14
Age_gr(33,55]     2.86      0.690    4.14 6.83e-04
Age_gr(55,99]     4.97      0.718    6.92 2.46e-06</code></pre>
<p>We now have two rows where the parameter name is constructed as variable name + exposure level: <code>Age_gr(33,55]</code> and <code>Age_gr(55, 99]</code>, each corresponding to a dummy variable for the exposure level given in the parameter name. As before, the reference level is by default the first level of the factor predictor, and is not shown explicitly in the regression table (we just happen to know that it is <code>(0,33]</code> from before). Note we have a nice and increasing trend with age: for the reference group, the average hemoglobin level is ca. 11.6 g/dl, which increases by ca. 2.9 g/dl for the 33-55 year old women, and by ca. 5.00 g/dl for the women over 55 (again relative to the reference group).</p>
</div>
<div id="interactions" class="section level3" number="9.4.3">
<h3><span class="header-section-number">9.4.3</span> Interactions</h3>
<p>If we already more at least two predictors in a model, we can include interaction terms between that allows to easily test for effect modification. In the formula notation, we can use a <code>*</code> between two (or more) predictors to indicate that we want to include both predictors and their interaction.</p>
<p>In our example, we may be interested to know if the association between PCV and hemoglobin level is the same for pre- and post-menopausal women: in other words, whether menopause can be considered an effect modifier for the PCV/hemoglobin association.</p>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb229-1"><a href="regression-linear.html#cb229-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> lm_ia <span class="ot">=</span> <span class="fu">lm</span>(Hb <span class="sc">~</span> PCV <span class="sc">*</span> Menopause, <span class="at">data =</span> hemoglobin)</span>
<span id="cb229-2"><a href="regression-linear.html#cb229-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">summary</span>(lm_ia)</span>
<span id="cb229-3"><a href="regression-linear.html#cb229-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb229-4"><a href="regression-linear.html#cb229-4" aria-hidden="true" tabindex="-1"></a>Call<span class="sc">:</span></span>
<span id="cb229-5"><a href="regression-linear.html#cb229-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(<span class="at">formula =</span> Hb <span class="sc">~</span> PCV <span class="sc">*</span> Menopause, <span class="at">data =</span> hemoglobin)</span>
<span id="cb229-6"><a href="regression-linear.html#cb229-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb229-7"><a href="regression-linear.html#cb229-7" aria-hidden="true" tabindex="-1"></a>Residuals<span class="sc">:</span></span>
<span id="cb229-8"><a href="regression-linear.html#cb229-8" aria-hidden="true" tabindex="-1"></a>    Min      1Q  Median      3Q     Max </span>
<span id="cb229-9"><a href="regression-linear.html#cb229-9" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="fl">2.3788</span> <span class="sc">-</span><span class="fl">0.8998</span>  <span class="fl">0.2202</span>  <span class="fl">0.7357</span>  <span class="fl">2.0212</span> </span>
<span id="cb229-10"><a href="regression-linear.html#cb229-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb229-11"><a href="regression-linear.html#cb229-11" aria-hidden="true" tabindex="-1"></a>Coefficients<span class="sc">:</span></span>
<span id="cb229-12"><a href="regression-linear.html#cb229-12" aria-hidden="true" tabindex="-1"></a>                 Estimate Std. Error t value <span class="fu">Pr</span>(<span class="sc">&gt;</span><span class="er">|</span>t<span class="sc">|</span>)   </span>
<span id="cb229-13"><a href="regression-linear.html#cb229-13" aria-hidden="true" tabindex="-1"></a>(Intercept)       <span class="fl">8.03861</span>    <span class="fl">2.06697</span>   <span class="fl">3.889</span>   <span class="fl">0.0013</span> <span class="sc">**</span></span>
<span id="cb229-14"><a href="regression-linear.html#cb229-14" aria-hidden="true" tabindex="-1"></a>PCV               <span class="fl">0.11200</span>    <span class="fl">0.05376</span>   <span class="fl">2.084</span>   <span class="fl">0.0536</span> . </span>
<span id="cb229-15"><a href="regression-linear.html#cb229-15" aria-hidden="true" tabindex="-1"></a>MenopauseYes      <span class="fl">3.86862</span>    <span class="fl">4.79874</span>   <span class="fl">0.806</span>   <span class="fl">0.4320</span>   </span>
<span id="cb229-16"><a href="regression-linear.html#cb229-16" aria-hidden="true" tabindex="-1"></a>PCV<span class="sc">:</span>MenopauseYes <span class="sc">-</span><span class="fl">0.02267</span>    <span class="fl">0.10854</span>  <span class="sc">-</span><span class="fl">0.209</span>   <span class="fl">0.8372</span>   </span>
<span id="cb229-17"><a href="regression-linear.html#cb229-17" aria-hidden="true" tabindex="-1"></a><span class="sc">---</span></span>
<span id="cb229-18"><a href="regression-linear.html#cb229-18" aria-hidden="true" tabindex="-1"></a>Signif. codes<span class="sc">:</span>  <span class="dv">0</span> <span class="st">&#39;***&#39;</span> <span class="fl">0.001</span> <span class="st">&#39;**&#39;</span> <span class="fl">0.01</span> <span class="st">&#39;*&#39;</span> <span class="fl">0.05</span> <span class="st">&#39;.&#39;</span> <span class="fl">0.1</span> <span class="st">&#39; &#39;</span> <span class="dv">1</span></span>
<span id="cb229-19"><a href="regression-linear.html#cb229-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb229-20"><a href="regression-linear.html#cb229-20" aria-hidden="true" tabindex="-1"></a>Residual standard error<span class="sc">:</span> <span class="fl">1.367</span> on <span class="dv">16</span> degrees of freedom</span>
<span id="cb229-21"><a href="regression-linear.html#cb229-21" aria-hidden="true" tabindex="-1"></a>Multiple R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.7273</span>,    Adjusted R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.6762</span> </span>
<span id="cb229-22"><a href="regression-linear.html#cb229-22" aria-hidden="true" tabindex="-1"></a>F<span class="sc">-</span>statistic<span class="sc">:</span> <span class="fl">14.23</span> on <span class="dv">3</span> and <span class="dv">16</span> DF,  p<span class="sc">-</span>value<span class="sc">:</span> <span class="fl">8.878e-05</span></span></code></pre></div>
<p>As we can see in the regression table, we now have three non-intercept covariates in the model:</p>
<ul>
<li>a main effect term for PCV, which is a continuous predictor;</li>
<li>a main effect term for menopausal status, which is coded as a dummy variable with exposure level <code>Yes</code>;</li>
<li>an interaction term between the two variables, indicated by the colon <code>:</code> between the two main effect parameter names.</li>
</ul>
<p>UNDER CONSTRUCTION Interactions are tricky beasts, and I won’t go into too much detail here; as a general rule, if in doubt, always write down the regression equation, including any dummy variables, and set the interaction variables to the actual arithmetic product of the contributing main effect variables: in our example, the variable corresponding to <code>PCV:MenopauseYes</code> has the same value as PCV whenever the menopausal status dummy is zero (i.e. pre-menopausal/reference level) and zero otherwise. This can then be used to understand which parameter contributes to the mean of which combination of exposure levels.</p>
<p>For the current example, we only have one interaction parameter. The corresponding null hypothesis is that the slope for the association between PCV and hemoglobin level is the same for pre- and post-menopausal women; given the rather large <span class="math inline">\(p=0.84\)</span>, we conclude that this data set does not procide sufficient evidence to reject this null hypothesis - in other words, there is no statistically significant interaction between PCV and menopausal status, and we prefer model <code>lm1</code> over model <code>lm4</code> here.</p>
</div>
<div id="splines" class="section level3" number="9.4.4">
<h3><span class="header-section-number">9.4.4</span> Splines</h3>
<p>Despite the name, we can use linear regression models for what are apparently “non-linear” associations between a predictor and an outcome variable, by adding transformations of the predictor variable to the model. The simplest case is a quadratic regression model:
<span class="math display">\[
y = \beta_0 + \beta_1 \times x + \beta_2 \times x^2
\]</span>
Despite being a multi-predictor linear regression model (with predictors <span class="math inline">\(x\)</span> and <span class="math inline">\(x^2\)</span>), this model can clearly capture associations between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> that do not follow a straight line.<a href="#fn52" class="footnote-ref" id="fnref52"><sup>52</sup></a></p>
<p>A more general variant of this idea (using multiple transformations of the same underlying variable as predictors) can be implemented via so-called <em>spline terms</em>. These are smoothing functions similar to the loess smoother we have seen in sub-section <a href="regression-linear.html#scatter-loess">9.3.1</a>, but designed to be included in a regression model rather than just for visual representation. Like the loess curves, splines have the ability to summarize a curvilinear relationship between two variables with a smooth curve.</p>
<p>In our example, we can add such a spline term via function <code>ns</code> in package <code>splines</code>. We simply apply <code>ns</code> to the variable for which we want to have a spline term include, in our case PCV:</p>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb230-1"><a href="regression-linear.html#cb230-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">require</span>(splines)</span>
<span id="cb230-2"><a href="regression-linear.html#cb230-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> lm_spl <span class="ot">&lt;-</span> <span class="fu">lm</span>(Hb <span class="sc">~</span> <span class="fu">ns</span>(PCV, <span class="at">df =</span> <span class="dv">3</span>), <span class="at">data =</span> hemoglobin)</span></code></pre></div>
<p>The second argument to <code>ns</code> are the <em>degrees of freedom</em>, which is the number of transformed variables (and therefore the number of regression parameters) that will be included in the model for the relationship between PCV and hemoglobin level; generally speaking, the more degrees of freedom we add, the more closely the curve will follow the data, and the fewer we use, the stronger the spline term will smooth out local variability. For our small data set, three degrees of freedom is seems like a suitable starting point.</p>
<p>Let’s look at the summary:</p>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb231-1"><a href="regression-linear.html#cb231-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">summary</span>(lm_spl)</span>
<span id="cb231-2"><a href="regression-linear.html#cb231-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb231-3"><a href="regression-linear.html#cb231-3" aria-hidden="true" tabindex="-1"></a>Call<span class="sc">:</span></span>
<span id="cb231-4"><a href="regression-linear.html#cb231-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(<span class="at">formula =</span> Hb <span class="sc">~</span> <span class="fu">ns</span>(PCV, <span class="at">df =</span> <span class="dv">3</span>), <span class="at">data =</span> hemoglobin)</span>
<span id="cb231-5"><a href="regression-linear.html#cb231-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb231-6"><a href="regression-linear.html#cb231-6" aria-hidden="true" tabindex="-1"></a>Residuals<span class="sc">:</span></span>
<span id="cb231-7"><a href="regression-linear.html#cb231-7" aria-hidden="true" tabindex="-1"></a>    Min      1Q  Median      3Q     Max </span>
<span id="cb231-8"><a href="regression-linear.html#cb231-8" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="fl">4.0040</span> <span class="sc">-</span><span class="fl">0.9718</span>  <span class="fl">0.1967</span>  <span class="fl">1.2750</span>  <span class="fl">2.2215</span> </span>
<span id="cb231-9"><a href="regression-linear.html#cb231-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb231-10"><a href="regression-linear.html#cb231-10" aria-hidden="true" tabindex="-1"></a>Coefficients<span class="sc">:</span></span>
<span id="cb231-11"><a href="regression-linear.html#cb231-11" aria-hidden="true" tabindex="-1"></a>                 Estimate Std. Error t value <span class="fu">Pr</span>(<span class="sc">&gt;</span><span class="er">|</span>t<span class="sc">|</span>)    </span>
<span id="cb231-12"><a href="regression-linear.html#cb231-12" aria-hidden="true" tabindex="-1"></a>(Intercept)         <span class="fl">9.003</span>      <span class="fl">1.546</span>   <span class="fl">5.824</span> <span class="fl">2.59e-05</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb231-13"><a href="regression-linear.html#cb231-13" aria-hidden="true" tabindex="-1"></a><span class="fu">ns</span>(PCV, <span class="at">df =</span> <span class="dv">3</span>)<span class="dv">1</span>    <span class="fl">3.340</span>      <span class="fl">1.435</span>   <span class="fl">2.328</span>  <span class="fl">0.03334</span> <span class="sc">*</span>  </span>
<span id="cb231-14"><a href="regression-linear.html#cb231-14" aria-hidden="true" tabindex="-1"></a><span class="fu">ns</span>(PCV, <span class="at">df =</span> <span class="dv">3</span>)<span class="dv">2</span>   <span class="fl">12.340</span>      <span class="fl">3.829</span>   <span class="fl">3.223</span>  <span class="fl">0.00531</span> <span class="sc">**</span> </span>
<span id="cb231-15"><a href="regression-linear.html#cb231-15" aria-hidden="true" tabindex="-1"></a><span class="fu">ns</span>(PCV, <span class="at">df =</span> <span class="dv">3</span>)<span class="dv">3</span>    <span class="fl">4.548</span>      <span class="fl">1.720</span>   <span class="fl">2.644</span>  <span class="fl">0.01770</span> <span class="sc">*</span>  </span>
<span id="cb231-16"><a href="regression-linear.html#cb231-16" aria-hidden="true" tabindex="-1"></a><span class="sc">---</span></span>
<span id="cb231-17"><a href="regression-linear.html#cb231-17" aria-hidden="true" tabindex="-1"></a>Signif. codes<span class="sc">:</span>  <span class="dv">0</span> <span class="st">&#39;***&#39;</span> <span class="fl">0.001</span> <span class="st">&#39;**&#39;</span> <span class="fl">0.01</span> <span class="st">&#39;*&#39;</span> <span class="fl">0.05</span> <span class="st">&#39;.&#39;</span> <span class="fl">0.1</span> <span class="st">&#39; &#39;</span> <span class="dv">1</span></span>
<span id="cb231-18"><a href="regression-linear.html#cb231-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb231-19"><a href="regression-linear.html#cb231-19" aria-hidden="true" tabindex="-1"></a>Residual standard error<span class="sc">:</span> <span class="fl">1.821</span> on <span class="dv">16</span> degrees of freedom</span>
<span id="cb231-20"><a href="regression-linear.html#cb231-20" aria-hidden="true" tabindex="-1"></a>Multiple R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.516</span>, Adjusted R<span class="sc">-</span>squared<span class="sc">:</span>  <span class="fl">0.4253</span> </span>
<span id="cb231-21"><a href="regression-linear.html#cb231-21" aria-hidden="true" tabindex="-1"></a>F<span class="sc">-</span>statistic<span class="sc">:</span> <span class="fl">5.686</span> on <span class="dv">3</span> and <span class="dv">16</span> DF,  p<span class="sc">-</span>value<span class="sc">:</span> <span class="fl">0.007581</span></span></code></pre></div>
<p>We get a typical regression output; the regression table shows four parameters verall, one intercept and three spline parameters, easily recognized by their name, and all of them statistically significantly different from zero at the usual <span class="math inline">\(\alpha = 0.05\)</span>. However, and this is one the disadvantages of spline variables, it is not really possible to interpret what they mean in terms of the underlying problem.</p>
<p>It is more interesting to plot the association between PCV and hemoglobin levels that the spline variables describe, which we can do via the functionn <code>termplot</code>:</p>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="regression-linear.html#cb232-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">termplot</span>(lm_spl)</span></code></pre></div>
<p><img src="introductio-to-r_files/figure-html/unnamed-chunk-245-1.png" width="80%" style="display: block; margin: auto;" />
We see that the spline curve actually captures the same small bump in the middle of the scatterplot that we have seen from the loess curve above.</p>
<p><strong>Exercise:</strong> You can experiment with <code>ns(PCV, df=k)</code> and <code>termplot</code> to study the shape of the spline curve for different values <span class="math inline">\(k\)</span> as degrees of freedom. What happens if you increase <span class="math inline">\(k\)</span>? When you decrease it? Is the expression “overfitting” appropriate in any setting?</p>
</div>
<div id="model-comparisons" class="section level3" number="9.4.5">
<h3><span class="header-section-number">9.4.5</span> Model comparisons</h3>
<p>We are reasonably often interested in comparing two regression models for the same data. If the two models are nested, i.e. all predictors variables of the smaller model are also included in the larger model, we can use an F-test to test the null hypothesis that both models explan the data equally well (i.e. the larger model does not contribute anything extra), via the function <code>anova</code>.</p>
<p>For our example, we may be interested in comparing the model with a simple linear association between PCV and hemoglobin level (<code>lm1</code>) and the spline model we have just fitted in the previous sub-section:<a href="#fn53" class="footnote-ref" id="fnref53"><sup>53</sup></a></p>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="regression-linear.html#cb233-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">anova</span>(lm1, lm_spl)</span>
<span id="cb233-2"><a href="regression-linear.html#cb233-2" aria-hidden="true" tabindex="-1"></a>Analysis of Variance Table</span>
<span id="cb233-3"><a href="regression-linear.html#cb233-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb233-4"><a href="regression-linear.html#cb233-4" aria-hidden="true" tabindex="-1"></a>Model <span class="dv">1</span><span class="sc">:</span> Hb <span class="sc">~</span> PCV</span>
<span id="cb233-5"><a href="regression-linear.html#cb233-5" aria-hidden="true" tabindex="-1"></a>Model <span class="dv">2</span><span class="sc">:</span> Hb <span class="sc">~</span> <span class="fu">ns</span>(PCV, <span class="at">df =</span> <span class="dv">3</span>)</span>
<span id="cb233-6"><a href="regression-linear.html#cb233-6" aria-hidden="true" tabindex="-1"></a>  Res.Df    RSS Df Sum of Sq      F <span class="fu">Pr</span>(<span class="sc">&gt;</span>F)</span>
<span id="cb233-7"><a href="regression-linear.html#cb233-7" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span>     <span class="dv">18</span> <span class="fl">59.910</span>                           </span>
<span id="cb233-8"><a href="regression-linear.html#cb233-8" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span>     <span class="dv">16</span> <span class="fl">53.051</span>  <span class="dv">2</span>    <span class="fl">6.8595</span> <span class="fl">1.0344</span>  <span class="fl">0.378</span></span></code></pre></div>
<p>Given the fairly large <span class="math inline">\(p=0.38\)</span>, we do not want to reject the null hypothesis here, and conclude that based on the evidence in our small sample, a linear relationship is appropriate here.</p>
<p>If the two models we want to compare are not nested (i.e. both models include at leats one predictor that is not part of the other model), we can use <em>Akaike’s Information criterion</em> (AIC): the AIC is a numerical measure for how well a model fits a data set which takes into account the number of predictors / regression coefficients used for the model, where smaller values indicate better fit.</p>
<p>If we want to compare the fully adjusted model <code>lm3</code> and the interaction model <code>lm_ia</code>, which are clearly not nested, we can look at their AICs:</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb234-1"><a href="regression-linear.html#cb234-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">AIC</span>(lm3)</span>
<span id="cb234-2"><a href="regression-linear.html#cb234-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">62.67548</span></span>
<span id="cb234-3"><a href="regression-linear.html#cb234-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">AIC</span>(lm_ia)</span>
<span id="cb234-4"><a href="regression-linear.html#cb234-4" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">74.79201</span></span></code></pre></div>
<p>Seeing that <code>lm3</code> has a clearly lower AIC, we would prefer <code>lm3</code> over <code>lm_ia</code>here.</p>
<p><strong>Exercise</strong>: Compare the <span class="math inline">\(R^2\)</span>- and adjusted <span class="math inline">\(R^2\)</span>-values for models <code>lm1</code> and <code>lm_spl</code>. In the light of the <code>anova</code>-results above, which value seems to describe the actual model fit better?</p>
</div>
</div>
<div id="technical-notes-4" class="section level2" number="9.5">
<h2><span class="header-section-number">9.5</span> Technical notes</h2>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="44">
<li id="fn44"><p>This is a very different for <em>non-linear</em> models… of which we will otherwise not talk.<a href="regression-linear.html#fnref44" class="footnote-back">↩︎</a></p></li>
<li id="fn45"><p>The smoothing function used by <code>scatter.smooth</code> and demonstrated above is called <a href="https://en.wikipedia.org/wiki/Local_regression">loess</a>, or <em>locally estimated scatterplot smoother</em>, and is primarily used for graphical summaries as shown here.<a href="regression-linear.html#fnref45" class="footnote-back">↩︎</a></p></li>
<li id="fn46"><p>Note that R also provides a very old-fashioned <code>*</code>-notation for the p-values, together with a legend explaining the notation. This is archaic and should be <del>burned with fire</del> ignored.<a href="regression-linear.html#fnref46" class="footnote-back">↩︎</a></p></li>
<li id="fn47"><p>Actually, we can fit an intercept-only model using the formula <code>Hb ~ 1</code> if we want to. As it happens, this a complicated way of estimating the mean hemoglobin level with a confidence interval.<a href="regression-linear.html#fnref47" class="footnote-back">↩︎</a></p></li>
<li id="fn48"><p>So with an increasing sample size, the width of the confidence intervals will converge to zero, because we have more and more information about the location of the regression line, but the width of the prediction interval will converge to ca. <span class="math inline">\(4\times \sigma\)</span>, or four times the residual standard error, because even if we know exactly where the regression line is, the individual points are going to be randomly scattered around it because of the error term <span class="math inline">\(\epsilon\)</span>.<a href="regression-linear.html#fnref48" class="footnote-back">↩︎</a></p></li>
<li id="fn49"><p>You can see the ordering of the factor levels in different ways: e.g. simply by displaying the factor variable in the console (<code>hemoglobin$Menopause</code>) lists the factors in order at the bottom; you can use the function <code>level</code> (as in <code>level(hemoglobin$Menopause)</code>) to extract only the levels, and when you tabulate the factor, the counts will also be presented in the order of the levels (<code>table(hemoglobin$Menopause)</code>).<a href="regression-linear.html#fnref49" class="footnote-back">↩︎</a></p></li>
<li id="fn50"><p>Of course, if we want to predict the outcome, we now have to specify values for all predictor variables in the model in the data frame passed to <code>predict</code>.<a href="regression-linear.html#fnref50" class="footnote-back">↩︎</a></p></li>
<li id="fn51"><p>Not really for this data set, but it’s a reasonable demonstration for categorizing a continuous variable, which is something that epidemiologists tend to do a lot… probably too much, actually: often a spline term will be a superior solution.<a href="regression-linear.html#fnref51" class="footnote-back">↩︎</a></p></li>
<li id="fn52"><p>I find it useful to speak in this situation of a <em>curvilinear</em> rather than a non-linear relationship, but not everybody agrees.<a href="regression-linear.html#fnref52" class="footnote-back">↩︎</a></p></li>
<li id="fn53"><p>It’s not obvious, but a linear term for a model (like <span class="math inline">\(\beta \times PCV\)</span>) is always nested in the corresponding spline term for the same variable (i.e. <code>ns(PCV, df=k)</code> for any <span class="math inline">\(k&gt;0\)</span>), so this is a test we can always do.<a href="regression-linear.html#fnref53" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="basic-stats-epi.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="regression-other.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/regression_linear.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["introductio-to-r.pdf", "introductio-to-r.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
